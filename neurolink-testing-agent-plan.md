# Lumos: AI-Powered Error Intelligence & Test Validation System
## Complete Implementation Plan - MVP (5-6 Days)

## ğŸ¯ Project Overview

### Primary Objective
Create **Lumos** - an intelligent testing agent that transforms how developers debug and validate tests using AI-powered analysis, pattern recognition, and community knowledge mining.

### Core Value Proposition
- **Reduce debugging time by 60%** through intelligent error analysis
- **Improve test quality by 85%** through AI-powered validation
- **Accelerate problem resolution** through community solution mining
- **Build organizational testing knowledge** through pattern learning

### Technology Stack
- **Language**: TypeScript (strict mode)
- **Browser Automation**: Playwright
- **AI Integration**: Neurolink SDK
- **Testing**: Playwright Test + Jest
- **CLI**: Commander.js

### Success Metrics
- >80% of suggestions are actionable
- <10 seconds average analysis time
- Developers find it useful for daily debugging

## Overview

This document outlines a comprehensive plan for using Juspay's Neurolink SDK to create an AI-powered testing agent focused on **error intelligence and test validation** rather than test generation. Based on extensive research, Neurolink is a Universal AI Development Platform that unifies multiple AI providers with intelligent fallback mechanisms, making it ideal for building sophisticated error analysis and debugging assistance.

## Research Findings

### What is Neurolink?

Neurolink is **NOT** a dedicated testing framework, but rather a Universal AI Development Platform with the following key characteristics:

- **Multi-Provider Integration**: Supports 9+ major AI providers (OpenAI, Anthropic, Google, Azure, etc.)
- **LiteLLM Integration**: Access to 100+ AI models through unified interface
- **MCP Server Integration**: Working Model Context Protocol support for advanced tool integration
- **Real-time Infrastructure**: WebSocket support for live interactions
- **Analytics Framework**: Built-in usage tracking, cost monitoring, and quality evaluation
- **Production Ready**: TypeScript SDK with professional CLI tools

### Key Capabilities for Error Intelligence

1. **Intelligent Provider Fallback**: Ensures reliability when specific AI providers fail
2. **Multi-Model Comparison**: Error analysis across different AI models simultaneously
3. **Analytics & Evaluation**: Built-in quality scoring and performance metrics
4. **Context Management**: MCP integration for maintaining state across complex debugging scenarios
5. **Real-time Processing**: Streaming capabilities for live error analysis feedback

## ğŸ“‹ Project Constraints and Scope

### âŒ What We Will NOT Do (Phase 1.5)
- **Component testing generation** - No automatic test creation
- **Click event tests or interaction tests** - No test generation without actual analysis
- **Visual/layout testing** - Deferred to later phases
- **API testing and security testing** - Not in current scope
- **Advanced testing capabilities** - Reserved for future phases

### âœ… What We WILL Do (Phase 1.5 Focus)
- **Error intelligence and analysis** - AI-powered failure analysis
- **Test validation** - Validate effectiveness of existing test cases
- **Fix suggestions** - Provide actionable debugging assistance
- **Web research integration** - Find community solutions for errors
- **Visual failure analysis** - Screenshot and DOM analysis for UI failures

### ğŸ¯ Phase-Based Implementation Strategy

**Phase 1.5 (1-3 days)**: UI & Functionality Testing Intelligence
- Goal: Build core error analysis and debugging assistance
- Focus: Immediate developer value through intelligent failure analysis
- Deliverable: Production-ready error intelligence system

**Phase 2 (1-3 days)**: API, Integration, Performance & Security Testing
- Goal: Expand testing capabilities to backend and security domains
- Focus: Comprehensive testing coverage across all application layers
- Deliverable: Full-stack testing intelligence platform

**Phase 3 (1-3 days)**: Intelligent Test Generation
- Goal: Generate contextually relevant tests based on learned patterns
- Focus: Proactive test creation using accumulated intelligence
- Deliverable: AI-powered test generation system

## ğŸš€ **Streamlined 3-Phase Implementation Plan (5-6 Days Total)**

### **Phase 1: Core Intelligence Foundation** (Days 1-2)
**Duration**: 2 days  
**Focus**: Build all core AI and analysis capabilities

#### **Step 1.1**: Error Analysis Engine Implementation  
**Duration**: Day 1 Morning (4 hours)
**Goal**: Multi-AI error classification system

#### **Step 1.2**: Neurolink Integration & AI Classification
**Duration**: Day 1 Afternoon (4 hours)  
**Goal**: Reliable AI service with multi-provider support

#### **Step 1.3**: Fix Generation Engine
**Duration**: Day 2 Morning (4 hours)
**Goal**: AI-powered fix suggestions with confidence scoring

#### **Step 1.4**: Test Validation Engine *(moved to Phase 1)*
**Duration**: Day 2 Morning (4 hours)
**Goal**: Test quality assessment and coverage analysis

#### **Step 1.5**: Web Research Integration *(moved to Phase 1)*
**Duration**: Day 2 Afternoon (4 hours)
**Goal**: Community solution mining with AI ranking

### **Phase 2: Interface & Integration** (Days 3-4)
**Duration**: 2 days
**Focus**: User interface and system integration

#### **Step 2.1**: CLI Interface Implementation *(moved to Phase 2)*
**Duration**: Day 3 Morning (4 hours)
**Goal**: Developer-friendly command interface

#### **Step 2.2**: Code Context Analysis with Playwright *(updated)*
**Duration**: Day 3 Afternoon (4 hours)
**Goal**: Deep code understanding and visual analysis

#### **Step 2.3**: Reporting System (HTML/JSON)
**Duration**: Day 4 Morning (4 hours)
**Goal**: Comprehensive result presentation

#### **Step 2.4**: Integration Testing & Validation
**Duration**: Day 4 Afternoon (4 hours)
**Goal**: End-to-end system validation

### **Phase 3: Polish & Package** (Days 5-6)
**Duration**: 1-2 days
**Focus**: Production readiness and deployment

#### **Step 3.1**: Error Handling & Production Readiness
**Duration**: Day 5 Morning (4 hours)
**Goal**: Robust error handling and validation

#### **Step 3.2**: Configuration Management
**Duration**: Day 5 Afternoon (4 hours)
**Goal**: Easy setup and configuration

#### **Step 3.3**: Documentation & Packaging
**Duration**: Day 6 Morning (4 hours)
**Goal**: Professional documentation and packaging

#### **Step 3.4**: Optional Basic Automation
**Duration**: Day 6 Afternoon (4 hours)
**Goal**: Basic file watching and Git integration (if time permits)

## ğŸ“Š **Success Metrics (Streamlined)**
- **Primary**: >80% of suggestions are actionable
- **Secondary**: <10 seconds average analysis time  
- **Tertiary**: Developers find it useful for daily debugging

#### 1.5.1 Core Error Intelligence Engine
**Duration**: Days 1-2

**Objectives:**
- Build the central error analysis orchestrator
- Implement multi-AI error classification system
- Create error pattern recognition capabilities
- Establish confidence scoring for suggestions

**Key Components:**
```typescript
class ErrorIntelligenceEngine {
  private neurolink: NeuroLink;
  private playwrightAnalyzer: PlaywrightFailureAnalyzer;
  private webSearcher: WebResearchService;
  private testValidator: TestValidator;

  async analyzeFailure(testFailure: TestFailure): Promise<ErrorAnalysisReport> {
    // 1. Classify error using multi-AI analysis
    const classification = await this.classifyError(testFailure);
    
    // 2. Extract code context around failure
    const codeContext = await this.extractCodeContext(testFailure);
    
    // 3. Analyze failure patterns
    const patterns = await this.analyzePatterns(testFailure);
    
    // 4. Generate visual analysis if UI-related
    let visualAnalysis = null;
    if (classification.category === 'ui' || classification.category === 'interaction') {
      visualAnalysis = await this.playwrightAnalyzer.analyzeUIFailure(testFailure);
    }
    
    // 5. Research similar errors online
    const webSolutions = await this.webSearcher.searchSolutions(testFailure);
    
    // 6. Generate fix suggestions
    const suggestions = await this.generateFixSuggestions(
      testFailure, classification, codeContext, visualAnalysis, webSolutions
    );
    
    return {
      testFailure,
      classification,
      codeContext,
      visualAnalysis,
      webSolutions,
      suggestions,
      confidence: this.calculateConfidence(suggestions),
      timestamp: new Date().toISOString()
    };
  }
}
```

**Error Classification Categories:**
1. **Logic Errors**: Business logic, validation, algorithmic issues
2. **Environment Issues**: Configuration, dependencies, setup problems
3. **Race Conditions**: Timing, async/await, concurrency issues
4. **UI/Interaction Issues**: DOM manipulation, event handling, rendering
5. **Network/API Issues**: HTTP requests, connectivity, data format
6. **Configuration Issues**: Environment variables, build configuration

#### 1.5.2 Playwright-Based Visual Failure Analysis
**Duration**: Days 2-3

**Objectives:**
- Capture visual evidence of UI failures
- Analyze DOM state at failure points
- Monitor network requests and console errors
- Extract relevant HTML/CSS causing issues

**Implementation:**
```typescript
class PlaywrightFailureAnalyzer {
  async analyzeUIFailure(error: TestFailure): Promise<VisualAnalysisReport> {
    const page = await this.browser.newPage();
    
    try {
      // Navigate to failure point
      await page.goto(error.context.url || error.context.testUrl);
      
      // Capture comprehensive failure state
      const screenshot = await page.screenshot({ 
        fullPage: true,
        type: 'png'
      });
      
      // Analyze DOM state around failure
      const domAnalysis = await this.analyzeDOMState(page, error);
      
      // Capture console errors
      const consoleErrors = await this.captureConsoleErrors(page);
      
      // Monitor network failures
      const networkIssues = await this.captureNetworkIssues(page);
      
      // Extract performance metrics
      const performanceMetrics = await this.capturePerformanceMetrics(page);
      
      // Analyze element accessibility
      const accessibilityIssues = await this.analyzeAccessibility(page, error);
      
      return {
        screenshot: screenshot.toString('base64'),
        domAnalysis,
        consoleErrors,
        networkIssues,
        performanceMetrics,
        accessibilityIssues,
        timestamp: new Date().toISOString()
      };
    } finally {
      await page.close();
    }
  }

  private async analyzeDOMState(page: Page, error: TestFailure): Promise<DOMAnalysis> {
    return await page.evaluate((errorContext) => {
      const targetElement = errorContext.selector ? 
        document.querySelector(errorContext.selector) : null;
      
      return {
        elementExists: !!targetElement,
        elementVisible: targetElement ? 
          window.getComputedStyle(targetElement).display !== 'none' : false,
        elementBounds: targetElement ? 
          targetElement.getBoundingClientRect() : null,
        elementAttributes: targetElement ? 
          Object.fromEntries(
            Array.from(targetElement.attributes).map(attr => [attr.name, attr.value])
          ) : null,
        computedStyles: targetElement ? 
          window.getComputedStyle(targetElement) : null,
        parentChain: this.getParentChain(targetElement),
        siblings: this.getSiblingInfo(targetElement),
        pageTitle: document.title,
        pageUrl: window.location.href,
        viewportSize: {
          width: window.innerWidth,
          height: window.innerHeight
        }
      };
    }, error.context);
  }
}
```

#### 1.5.3 Test Validation Engine
**Duration**: Days 3-4

**Objectives:**
- Analyze existing test suites for quality and effectiveness
- Identify coverage gaps and improvement opportunities
- Detect flaky tests and suggest stabilization
- Provide actionable recommendations for test improvements

**Implementation:**
```typescript
class TestValidator {
  async validateTestSuite(testDirectory: string): Promise<TestValidationReport> {
    // 1. Discover all test files
    const testFiles = await this.discoverTestFiles(testDirectory);
    
    // 2. Analyze test quality metrics
    const qualityMetrics = await this.analyzeTestQuality(testFiles);
    
    // 3. Identify coverage gaps
    const coverageGaps = await this.identifyCoverageGaps(testFiles);
    
    // 4. Detect problematic patterns
    const problemPatterns = await this.detectProblematicPatterns(testFiles);
    
    // 5. Generate improvement suggestions
    const suggestions = await this.generateImprovementSuggestions({
      qualityMetrics,
      coverageGaps,
      problemPatterns
    });
    
    return {
      summary: {
        totalTests: testFiles.length,
        qualityScore: this.calculateOverallQualityScore(qualityMetrics),
        criticalIssues: problemPatterns.filter(p => p.severity === 'critical').length
      },
      qualityMetrics,
      coverageGaps,
      problemPatterns,
      suggestions,
      generatedAt: new Date().toISOString()
    };
  }

  private async analyzeTestQuality(testFiles: TestFile[]): Promise<QualityMetrics[]> {
    const metrics = [];
    
    for (const testFile of testFiles) {
      const content = await fs.readFile(testFile.path, 'utf-8');
      
      const fileMetrics = {
        file: testFile.path,
        maintainabilityScore: this.calculateMaintainabilityScore(content),
        effectivenessScore: await this.calculateEffectivenessScore(content),
        readabilityScore: this.calculateReadabilityScore(content),
        redundancyIssues: this.detectRedundancy(content),
        flakinessIndicators: this.detectFlakinessIndicators(content),
        bestPracticeViolations: this.detectBestPracticeViolations(content)
      };
      
      metrics.push(fileMetrics);
    }
    
    return metrics;
  }
}
```

**Test Quality Assessment Areas:**
1. **Effectiveness Score**: How well tests catch real issues
2. **Maintainability Score**: How easy tests are to maintain and update
3. **Coverage Analysis**: What scenarios are missing or inadequately tested
4. **Redundancy Detection**: Overlapping or duplicate test cases
5. **Flakiness Detection**: Tests that fail intermittently
6. **Best Practice Compliance**: Following testing best practices

#### 1.5.4 Web Research & Solution Mining
**Duration**: Days 4-5

**Objectives:**
- Search Stack Overflow, GitHub, and documentation for similar errors
- Extract and rank relevant solutions using AI
- Build a knowledge base of error patterns and solutions
- Provide community-validated fix suggestions

**Implementation:**
```typescript
class WebResearchService {
  async searchSolutions(error: TestFailure): Promise<WebSolutionResults> {
    // Generate intelligent search queries
    const queries = this.generateSearchQueries(error);
    
    // Search multiple sources in parallel
    const [stackOverflowResults, githubResults, docsResults] = await Promise.all([
      this.searchStackOverflow(queries),
      this.searchGitHubIssues(queries),
      this.searchDocumentation(queries)
    ]);
    
    // Combine and filter results
    const allResults = [...stackOverflowResults, ...githubResults, ...docsResults];
    
    // AI-powered relevance analysis and ranking
    const rankedSolutions = await this.rankSolutions(allResults, error);
    
    return {
      originalQueries: queries,
      totalResults: allResults.length,
      relevantSolutions: rankedSolutions,
      searchSources: ['stackoverflow', 'github', 'documentation'],
      confidenceScores: rankedSolutions.map(s => s.confidence)
    };
  }

  private generateSearchQueries(error: TestFailure): string[] {
    const errorMessage = error.message.replace(/['"]/g, '');
    const framework = error.context.framework || 'javascript';
    const testFramework = error.context.testFramework || 'jest';
    
    return [
      `"${errorMessage}" ${framework} ${testFramework}`,
      `${error.type} ${framework} test failure solution`,
      `"${errorMessage}" stackoverflow solved`,
      `${framework} testing ${error.type} fix`,
      `how to fix "${errorMessage}" in ${framework} tests`,
      `${testFramework} ${error.type} error troubleshooting`
    ];
  }

  private async rankSolutions(
    solutions: SearchResult[], 
    error: TestFailure
  ): Promise<RankedSolution[]> {
    const analysisPrompt = `Analyze these search results for solutions to this test error:
    
    Error: ${error.message}
    Type: ${error.type}
    Framework: ${error.context.framework}
    Test Framework: ${error.context.testFramework}
    
    Search Results:
    ${solutions.map(result => `
    Title: ${result.title}
    Source: ${result.source}
    URL: ${result.url}
    Snippet: ${result.snippet}
    Score: ${result.score}
    `).join('\n')}
    
    For each relevant result, provide:
    1. Relevance score (1-10)
    2. Solution type (fix, workaround, explanation, documentation)
    3. Confidence level (high, medium, low)
    4. Key insights or code changes
    5. Implementation difficulty (easy, medium, hard)
    6. Potential risks or side effects
    
    Return only results with relevance score >= 6, ranked by overall utility.`;

    const analysis = await this.neurolink.generate({
      input: { text: analysisPrompt },
      context: {
        taskType: 'solution-ranking',
        errorType: error.type,
        framework: error.context.framework
      }
    });

    return this.parseSolutionAnalysis(analysis, solutions);
  }
}
```

#### 1.5.5 AI-Powered Fix Suggestion Engine
**Duration**: Days 5-6

**Objectives:**
- Generate comprehensive fix suggestions using multiple AI models
- Provide step-by-step implementation instructions
- Include code diffs and exact changes needed
- Score confidence and assess implementation difficulty

**Implementation:**
```typescript
class FixSuggestionEngine {
  async generateFixSuggestions(
    error: TestFailure,
    classification: ErrorClassification,
    codeContext: CodeContext,
    visualAnalysis: VisualAnalysisReport | null,
    webSolutions: WebSolutionResults
  ): Promise<FixSuggestion[]> {
    
    // Generate suggestions using multiple AI providers for consensus
    const suggestionPrompts = this.buildSuggestionPrompts(
      error, classification, codeContext, visualAnalysis, webSolutions
    );
    
    const suggestions = await Promise.all([
      this.neurolink.generate({ 
        provider: 'openai/gpt-4o', 
        input: { text: suggestionPrompts.detailed },
        context: { approach: 'detailed-analysis' }
      }),
      this.neurolink.generate({ 
        provider: 'anthropic/claude-3-5-sonnet', 
        input: { text: suggestionPrompts.alternative },
        context: { approach: 'alternative-solutions' }
      }),
      this.neurolink.generate({ 
        provider: 'google/gemini-pro', 
        input: { text: suggestionPrompts.preventive },
        context: { approach: 'preventive-measures' }
      })
    ]);
    
    // Parse and consolidate suggestions
    const parsedSuggestions = suggestions.map(s => this.parseSuggestion(s));
    
    // Cross-validate and score
    const scoredSuggestions = await this.scoreAndValidateSuggestions(
      parsedSuggestions, error, webSolutions
    );
    
    return scoredSuggestions.sort((a, b) => b.confidence - a.confidence);
  }

  private buildSuggestionPrompts(
    error: TestFailure,
    classification: ErrorClassification,
    codeContext: CodeContext,
    visualAnalysis: VisualAnalysisReport | null,
    webSolutions: WebSolutionResults
  ) {
    const baseContext = `
    Error Details:
    - Message: ${error.message}
    - Type: ${error.type}
    - Classification: ${classification.category} (${classification.severity})
    - Stack Trace: ${error.stackTrace}
    
    Code Context:
    ${codeContext.relevantCode}
    
    Visual Analysis: ${visualAnalysis ? JSON.stringify(visualAnalysis, null, 2) : 'N/A'}
    
    Community Solutions Found:
    ${webSolutions.relevantSolutions.map(sol => `- ${sol.title}: ${sol.insights}`).join('\n')}
    `;

    return {
      detailed: `${baseContext}
      
      Generate a comprehensive, step-by-step fix for this error. Focus on:
      1. Root cause analysis
      2. Primary solution with exact code changes
      3. Step-by-step implementation instructions
      4. Code diffs showing before/after
      5. Verification steps to confirm the fix works
      
      Provide specific, actionable guidance that a developer can follow immediately.`,
      
      alternative: `${baseContext}
      
      Generate alternative approaches to fixing this error. Focus on:
      1. Multiple different solution strategies
      2. Workarounds if direct fix is complex
      3. Trade-offs between different approaches
      4. When to use each alternative
      5. Migration paths from workarounds to permanent fixes`,
      
      preventive: `${baseContext}
      
      Generate preventive measures and best practices to avoid this error in the future. Focus on:
      1. Code patterns that prevent this type of error
      2. Testing strategies to catch this earlier
      3. Development workflow improvements
      4. Static analysis or linting rules
      5. Documentation and team knowledge sharing`
    };
  }
}
```

#### 1.5.6 CLI Interface & Reporting Dashboard
**Duration**: Days 6-7

**Objectives:**
- Create intuitive command-line interface for developers
- Build rich HTML reports with visual evidence
- Provide interactive debugging assistance
- Enable integration with existing development workflows

**CLI Commands:**
```bash
# Analyze specific test failure
neurolink-ai analyze --test-file="./tests/user.test.js" --failure-line=45

# Validate entire test suite
neurolink-ai validate --test-directory="./tests" --output="./test-analysis-report.html"

# Interactive debugging session
neurolink-ai debug --interactive

# Watch mode for continuous analysis
neurolink-ai watch --test-directory="./tests"

# Generate comprehensive report
neurolink-ai report --include-screenshots --include-solutions --format=html
```

**Dashboard Features:**
- **Visual Failure Evidence**: Screenshots with annotated problem areas
- **Interactive Fix Suggestions**: Expandable code diffs with confidence scores
- **Test Quality Heatmap**: Visual representation of test suite health
- **Solution Knowledge Base**: Searchable database of past solutions
- **Trend Analysis**: Error patterns over time

---

## ğŸ“ Project Structure & Directory Organization

### ğŸ—ï¸ Core Architecture Goals
Create a maintainable, scalable codebase that supports incremental development and easy extension for future phases.

### ğŸ“‚ Directory Structure with Goals

```
neurolink-error-intelligence/
â”œâ”€â”€ src/                                    # ğŸ¯ Goal: Core application source code
â”‚   â”œâ”€â”€ core/                              # ğŸ¯ Goal: Central orchestration and shared interfaces
â”‚   â”‚   â”œâ”€â”€ interfaces/                    # ğŸ“‹ Define contracts between components
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorAnalysis.ts          # Error analysis data structures
â”‚   â”‚   â”‚   â”œâ”€â”€ TestValidation.ts         # Test validation interfaces
â”‚   â”‚   â”‚   â”œâ”€â”€ WebResearch.ts            # Web research result structures
â”‚   â”‚   â”‚   â””â”€â”€ Reporting.ts              # Report generation interfaces
â”‚   â”‚   â”œâ”€â”€ types/                        # ğŸ“‹ TypeScript type definitions for type safety
â”‚   â”‚   â”œâ”€â”€ errors/                       # ğŸ“‹ Custom error classes for robust error handling
â”‚   â”‚   â””â”€â”€ constants/                    # ğŸ“‹ Application constants and enumerations
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                         # ğŸ¯ Goal: External service integrations and data access
â”‚   â”‚   â”œâ”€â”€ neurolink/                    # ğŸ¤– Neurolink SDK abstraction and management
â”‚   â”‚   â”œâ”€â”€ analysis/                     # ğŸ” Error analysis and pattern recognition services
â”‚   â”‚   â”œâ”€â”€ research/                     # ğŸŒ Web research and solution mining services
â”‚   â”‚   â””â”€â”€ storage/                      # ğŸ’¾ Data persistence and caching services
â”‚   â”‚
â”‚   â”œâ”€â”€ components/                       # ğŸ¯ Goal: Core business logic and analysis engines
â”‚   â”‚   â”œâ”€â”€ analyzer/                     # ğŸ”¬ Error analysis and classification engines
â”‚   â”‚   â”œâ”€â”€ validator/                    # âœ… Test validation and quality assessment
â”‚   â”‚   â”œâ”€â”€ suggester/                    # ğŸ’¡ Fix suggestion generation and ranking
â”‚   â”‚   â””â”€â”€ reporter/                     # ğŸ“Š Report generation and visualization
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                           # ğŸ¯ Goal: Shared utilities and helper functions
â”‚   â”‚   â”œâ”€â”€ config/                      # âš™ï¸ Configuration management and loading
â”‚   â”‚   â”œâ”€â”€ logger/                      # ğŸ“ Logging and debugging utilities
â”‚   â”‚   â”œâ”€â”€ helpers/                     # ğŸ› ï¸ Common helper functions and utilities
â”‚   â”‚   â””â”€â”€ parsers/                     # ğŸ“„ Code and data parsing utilities
â”‚   â”‚
â”‚   â””â”€â”€ cli/                            # ğŸ¯ Goal: Command-line interface and developer experience
â”‚       â”œâ”€â”€ commands/                    # ğŸ’» CLI command implementations
â”‚       â”œâ”€â”€ interactive/                 # ğŸ¤ Interactive debugging sessions
â”‚       â””â”€â”€ index.ts                     # ğŸšª CLI entry point and command registration
â”‚
â”œâ”€â”€ tests/                              # ğŸ¯ Goal: Comprehensive testing coverage
â”‚   â”œâ”€â”€ unit/                          # ğŸ§ª Unit tests for individual components
â”‚   â”œâ”€â”€ integration/                   # ğŸ”— Integration tests for component interactions
â”‚   â”œâ”€â”€ fixtures/                      # ğŸ“‹ Test data and mock responses
â”‚   â””â”€â”€ mocks/                         # ğŸ­ Mock implementations for testing
â”‚
â”œâ”€â”€ docs/                              # ğŸ¯ Goal: Comprehensive documentation
â”‚   â”œâ”€â”€ api/                           # ğŸ“š API documentation and examples
â”‚   â”œâ”€â”€ architecture/                  # ğŸ›ï¸ Architecture diagrams and decisions
â”‚   â”œâ”€â”€ examples/                      # ğŸ“– Usage examples and tutorials
â”‚   â””â”€â”€ guides/                        # ğŸ“‹ Implementation and setup guides
â”‚
â”œâ”€â”€ config/                            # ğŸ¯ Goal: Environment-specific configurations
â””â”€â”€ scripts/                           # ğŸ¯ Goal: Build, test, and deployment automation
```

## ğŸ”§ Detailed Phase 1.5 Implementation Guide
### Step-by-Step Technical Implementation with Testing Strategy

#### ğŸ¯ Implementation Goals
- **Goal 1**: Create modular, testable components that can be developed independently
- **Goal 2**: Establish robust interfaces that support future extensibility
- **Goal 3**: Implement comprehensive testing at each development step
- **Goal 4**: Build production-ready code with proper error handling

#### ğŸ“‹ Implementation Architecture & Strategy

**Core Design Principles:**
1. **Modular Architecture**: Each component can be developed and tested independently
2. **Interface-Driven Development**: Clear contracts between components
3. **Test-First Approach**: Unit tests before implementation, integration tests before progression
4. **Multiple Implementation Options**: Provide flexibility and fallback strategies
5. **Progressive Enhancement**: Start simple, add complexity incrementally

---

### Step 1: Project Foundation & Architecture Setup
**â±ï¸ Duration**: Day 1 (Morning - 4 hours)  
**Priority**: Critical - Foundation for all subsequent development

#### ğŸ¯ Step 1 Goals
- **Primary Goal**: Establish robust project foundation with clear interfaces
- **Secondary Goal**: Create type-safe development environment
- **Tertiary Goal**: Set up testing infrastructure for reliable development

#### ğŸ“‹ Success Criteria
- All directory structures created and validated
- Core interfaces defined with comprehensive TypeScript types
- TypeScript compilation successful with strict mode
- Basic testing infrastructure operational

#### 1.1 Project Structure Setup

**Enhanced Project Structure:**
```
neurolink-error-intelligence/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ interfaces/           # Core interfaces and contracts
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorAnalysis.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ TestValidation.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ WebResearch.ts
â”‚   â”‚   â”‚   â””â”€â”€ Reporting.ts
â”‚   â”‚   â”œâ”€â”€ types/               # TypeScript type definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorTypes.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ AnalysisTypes.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ ValidationTypes.ts
â”‚   â”‚   â”‚   â””â”€â”€ ConfigTypes.ts
â”‚   â”‚   â”œâ”€â”€ errors/              # Custom error classes
â”‚   â”‚   â”‚   â”œâ”€â”€ AnalysisError.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ ValidationError.ts
â”‚   â”‚   â”‚   â””â”€â”€ ConfigurationError.ts
â”‚   â”‚   â””â”€â”€ constants/           # Application constants
â”‚   â”‚       â”œâ”€â”€ ErrorCategories.ts
â”‚   â”‚       â”œâ”€â”€ Providers.ts
â”‚   â”‚       â””â”€â”€ Classifications.ts
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ neurolink/           # Neurolink SDK abstraction
â”‚   â”‚   â”‚   â”œâ”€â”€ NeuroLinkService.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ ProviderManager.ts
â”‚   â”‚   â”‚   â””â”€â”€ ResponseParser.ts
â”‚   â”‚   â”œâ”€â”€ analysis/            # Error analysis services
â”‚   â”‚   â”‚   â”œâ”€â”€ ClassificationService.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ ContextService.ts
â”‚   â”‚   â”‚   â””â”€â”€ PatternService.ts
â”‚   â”‚   â”œâ”€â”€ research/            # Web research services
â”‚   â”‚   â”‚   â”œâ”€â”€ SearchService.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ StackOverflowAPI.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ GitHubAPI.ts
â”‚   â”‚   â”‚   â””â”€â”€ SolutionAggregator.ts
â”‚   â”‚   â””â”€â”€ storage/             # Data persistence
â”‚   â”‚       â”œâ”€â”€ ErrorDatabase.ts
â”‚   â”‚       â”œâ”€â”€ CacheManager.ts
â”‚   â”‚       â””â”€â”€ KnowledgeBase.ts
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ analyzer/            # Error analyzer implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorClassificationEngine.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ CodeContextAnalyzer.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ VisualAnalyzer.ts
â”‚   â”‚   â”‚   â””â”€â”€ PatternAnalyzer.ts
â”‚   â”‚   â”œâ”€â”€ validator/           # Test validator implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ TestQualityValidator.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ CoverageAnalyzer.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ FlakinessDetector.ts
â”‚   â”‚   â”‚   â””â”€â”€ BestPracticeChecker.ts
â”‚   â”‚   â”œâ”€â”€ suggester/           # Fix suggestion components
â”‚   â”‚   â”‚   â”œâ”€â”€ FixSuggestionEngine.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ ConfidenceScorer.ts
â”‚   â”‚   â”‚   â””â”€â”€ SolutionValidator.ts
â”‚   â”‚   â””â”€â”€ reporter/            # Report generation
â”‚   â”‚       â”œâ”€â”€ HTMLReporter.ts
â”‚   â”‚       â”œâ”€â”€ JSONReporter.ts
â”‚   â”‚       â”œâ”€â”€ CLIReporter.ts
â”‚   â”‚       â””â”€â”€ DashboardReporter.ts
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ config/              # Configuration management
â”‚   â”‚   â”‚   â”œâ”€â”€ ConfigLoader.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ EnvironmentConfig.ts
â”‚   â”‚   â”‚   â””â”€â”€ DefaultConfig.ts
â”‚   â”‚   â”œâ”€â”€ logger/              # Logging utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ Logger.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ LogLevel.ts
â”‚   â”‚   â”‚   â””â”€â”€ LogFormatters.ts
â”‚   â”‚   â”œâ”€â”€ helpers/             # Common helper functions
â”‚   â”‚   â”‚   â”œâ”€â”€ StringUtils.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUtils.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ AsyncUtils.ts
â”‚   â”‚   â”‚   â””â”€â”€ ValidationUtils.ts
â”‚   â”‚   â””â”€â”€ parsers/             # Code and data parsers
â”‚   â”‚       â”œâ”€â”€ ASTParser.ts
â”‚   â”‚       â”œâ”€â”€ StackTraceParser.ts
â”‚   â”‚       â””â”€â”€ ErrorMessageParser.ts
â”‚   â””â”€â”€ cli/                     # Command-line interface
â”‚       â”œâ”€â”€ commands/
â”‚       â”‚   â”œâ”€â”€ AnalyzeCommand.ts
â”‚       â”‚   â”œâ”€â”€ ValidateCommand.ts
â”‚       â”‚   â”œâ”€â”€ ReportCommand.ts
â”‚       â”‚   â””â”€â”€ ConfigCommand.ts
â”‚       â”œâ”€â”€ interactive/
â”‚       â”‚   â”œâ”€â”€ InteractiveSession.ts
â”‚       â”‚   â””â”€â”€ PromptHandlers.ts
â”‚       â””â”€â”€ index.ts
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                    # Unit tests
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”œâ”€â”€ integration/             # Integration tests
â”‚   â”‚   â”œâ”€â”€ neurolink-integration/
â”‚   â”‚   â”œâ”€â”€ end-to-end/
â”‚   â”‚   â””â”€â”€ performance/
â”‚   â”œâ”€â”€ fixtures/                # Test data and fixtures
â”‚   â”‚   â”œâ”€â”€ error-samples/
â”‚   â”‚   â”œâ”€â”€ test-files/
â”‚   â”‚   â”œâ”€â”€ mock-responses/
â”‚   â”‚   â””â”€â”€ configuration/
â”‚   â””â”€â”€ mocks/                   # Mock implementations
â”‚       â”œâ”€â”€ MockNeuroLink.ts
â”‚       â”œâ”€â”€ MockFileSystem.ts
â”‚       â””â”€â”€ MockWebServices.ts
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ api/                     # API documentation
â”‚   â”œâ”€â”€ architecture/            # Architecture diagrams
â”‚   â”œâ”€â”€ examples/                # Usage examples
â”‚   â””â”€â”€ guides/                  # Implementation guides
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ default.json
â”‚   â”œâ”€â”€ development.json
â”‚   â”œâ”€â”€ production.json
â”‚   â””â”€â”€ test.json
â””â”€â”€ scripts/
    â”œâ”€â”€ build.sh
    â”œâ”€â”€ test.sh
    â””â”€â”€ deploy.sh
```

#### 1.2 Core Interface Definitions

**Core TypeScript Interfaces:**

```typescript
// src/core/interfaces/ErrorAnalysis.ts
export interface TestFailure {
  id: string;
  type: 'syntax' | 'runtime' | 'assertion' | 'timeout' | 'network' | 'configuration';
  message: string;
  stackTrace: string;
  testFile: string;
  lineNumber?: number;
  columnNumber?: number;
  context: TestContext;
  timestamp: string;
  severity: 'critical' | 'high' | 'medium' | 'low';
  metadata: {
    testRunner: string;
    testFramework: string;
    nodeVersion?: string;
    browserVersion?: string;
    operatingSystem: string;
  };
}

export interface TestContext {
  testName: string;
  testSuite: string;
  framework: 'jest' | 'mocha' | 'cypress' | 'playwright' | 'vitest' | 'other';
  url?: string;
  selector?: string;
  environment: 'development' | 'staging' | 'production' | 'ci';
  dependencies: string[];
  configuration: Record<string, any>;
}

export interface ErrorClassification {
  category: 'logic' | 'environment' | 'race-condition' | 'ui' | 'network' | 'configuration';
  subCategory: string;
  severity: 'critical' | 'high' | 'medium' | 'low';
  confidence: number; // 0-1
  rootCause: string;
  requiredExpertise: 'beginner' | 'intermediate' | 'advanced';
  tags: string[];
  similarityScore?: number;
  reasoning: string;
}

export interface CodeContext {
  relevantCode: string;
  surroundingLines: CodeLine[];
  imports: ImportStatement[];
  functions: FunctionContext[];
  variables: VariableContext[];
  dependencies: DependencyInfo[];
  fileStructure: FileStructureInfo;
  syntaxTree?: ASTNode;
}

export interface CodeLine {
  lineNumber: number;
  content: string;
  isHighlighted: boolean;
  annotation?: string;
}

export interface FixSuggestion {
  id: string;
  title: string;
  description: string;
  implementation: ImplementationGuide;
  confidence: number; // 0-1
  alternatives: AlternativeSolution[];
  risks: RiskAssessment[];
  verification: VerificationStep[];
  estimatedImpact: ImpactAssessment;
  prerequisites: string[];
  relatedSuggestions: string[];
}

export interface ImplementationGuide {
  steps: ImplementationStep[];
  codeDiff?: CodeDiff;
  estimatedTime: number; // minutes
  difficulty: 'easy' | 'medium' | 'hard';
  automatable: boolean;
  requiresManualIntervention: boolean;
}

export interface ErrorAnalysisReport {
  id: string;
  testFailure: TestFailure;
  classification: ErrorClassification;
  codeContext: CodeContext;
  visualAnalysis?: VisualAnalysisReport;
  webSolutions: WebSolutionResults;
  suggestions: FixSuggestion[];
  confidence: number;
  analysisTime: number; // milliseconds
  timestamp: string;
  version: string;
  metadata: AnalysisMetadata;
}
```

```typescript
// src/core/interfaces/TestValidation.ts
export interface TestValidationReport {
  summary: ValidationSummary;
  qualityMetrics: QualityMetrics[];
  coverageGaps: CoverageGap[];
  problemPatterns: ProblemPattern[];
  suggestions: ImprovementSuggestion[];
  trends: ValidationTrend[];
  generatedAt: string;
  version: string;
}

export interface QualityMetrics {
  file: string;
  maintainabilityScore: number; // 0-100
  effectivenessScore: number; // 0-100
  readabilityScore: number; // 0-100
  redundancyIssues: RedundancyIssue[];
  flakinessIndicators: FlakinessIndicator[];
  bestPracticeViolations: BestPracticeViolation[];
  complexity: ComplexityMetrics;
  coverage: CoverageMetrics;
}

export interface CoverageGap {
  type: 'function' | 'branch' | 'statement' | 'scenario';
  description: string;
  location: CodeLocation;
  severity: 'critical' | 'high' | 'medium' | 'low';
  suggestedTests: string[];
  estimatedEffort: number; // hours
}
```

```typescript
// src/core/interfaces/WebResearch.ts
export interface WebSolutionResults {
  originalQueries: string[];
  totalResults: number;
  relevantSolutions: RankedSolution[];
  searchSources: SearchSource[];
  confidenceScores: number[];
  researchTime: number; // milliseconds
  cacheHitRate: number;
}

export interface RankedSolution {
  id: string;
  title: string;
  url: string;
  source: 'stackoverflow' | 'github' | 'documentation' | 'blog' | 'forum';
  relevanceScore: number; // 0-10
  solutionType: 'fix' | 'workaround' | 'explanation' | 'documentation';
  confidence: 'high' | 'medium' | 'low';
  insights: string;
  implementation: SolutionImplementation;
  difficulty: 'easy' | 'medium' | 'hard';
  risks: string[];
  upvotes?: number;
  acceptedAnswer?: boolean;
  lastUpdated: string;
}

export interface SearchSource {
  name: string;
  endpoint: string;
  enabled: boolean;
  rateLimits: RateLimit;
  authentication?: AuthConfig;
}
```

#### 1.3 Implementation Options for Architecture

**Option A: Monolithic Service Architecture**
```typescript
// Single service handling all analysis
export class ErrorIntelligenceService {
  constructor(
    private config: ServiceConfig,
    private neurolinkService: NeuroLinkService
  ) {}

  async analyzeError(failure: TestFailure): Promise<ErrorAnalysisReport> {
    // All functionality consolidated in one service
    const classification = await this.classifyError(failure);
    const codeContext = await this.analyzeCodeContext(failure);
    const visualAnalysis = await this.performVisualAnalysis(failure);
    const webSolutions = await this.researchSolutions(failure);
    const suggestions = await this.generateSuggestions(failure, classification, codeContext);

    return {
      testFailure: failure,
      classification,
      codeContext,
      visualAnalysis,
      webSolutions,
      suggestions,
      confidence: this.calculateOverallConfidence([classification, suggestions]),
      timestamp: new Date().toISOString()
    };
  }
}

// Pros: Simple to implement and deploy
// Cons: Difficult to test individual components, tight coupling
```

**Option B: Microservices Architecture**
```typescript
// Separate services for each concern
export class ErrorIntelligenceOrchestrator {
  constructor(
    private classificationService: ErrorClassificationService,
    private contextService: CodeContextService,
    private visualService: VisualAnalysisService,
    private researchService: WebResearchService,
    private suggestionService: FixSuggestionService
  ) {}

  async analyzeError(failure: TestFailure): Promise<ErrorAnalysisReport> {
    // Coordinate between independent services
    const [classification, codeContext, webSolutions] = await Promise.all([
      this.classificationService.classify(failure),
      this.contextService.analyze(failure),
      this.researchService.research(failure)
    ]);

    const visualAnalysis = await this.visualService.analyze(failure, classification);
    const suggestions = await this.suggestionService.generate(
      failure, classification, codeContext, webSolutions
    );

    return this.assembleReport(failure, classification, codeContext, visualAnalysis, webSolutions, suggestions);
  }
}

// Pros: Clear separation of concerns, testable components
// Cons: More complex coordination, potential performance overhead
```

**Option C: Plugin-Based Architecture** â­ **Recommended**
```typescript
// Extensible plugin system for maximum flexibility
export interface AnalysisPlugin {
  name: string;
  version: string;
  dependencies: string[];
  analyze(failure: TestFailure, context: AnalysisContext): Promise<Partial<ErrorAnalysisReport>>;
  validate(input: any): boolean;
  getConfiguration(): PluginConfiguration;
}

export class ErrorIntelligenceEngine {
  private plugins: Map<string, AnalysisPlugin> = new Map();
  private pluginGraph: PluginDependencyGraph;

  constructor(private config: EngineConfig) {
    this.pluginGraph = new PluginDependencyGraph();
  }

  registerPlugin(plugin: AnalysisPlugin): void {
    this.validatePlugin(plugin);
    this.plugins.set(plugin.name, plugin);
    this.pluginGraph.addPlugin(plugin);
  }

  async analyzeError(failure: TestFailure): Promise<ErrorAnalysisReport> {
    const executionPlan = this.pluginGraph.createExecutionPlan();
    const analysisContext = new AnalysisContext(failure);
    const report = new ErrorAnalysisReport();

    for (const pluginGroup of executionPlan) {
      const results = await Promise.all(
        pluginGroup.map(pluginName => {
          const plugin = this.plugins.get(pluginName)!;
          return plugin.analyze(failure, analysisContext);
        })
      );

      // Merge results into the report
      results.forEach(result => report.merge(result));
      analysisContext.update(report);
    }

    return report;
  }
}

// Built-in plugins
export class ErrorClassificationPlugin implements AnalysisPlugin {
  name = 'error-classification';
  version = '1.0.0';
  dependencies = ['neurolink-service'];

  async analyze(failure: TestFailure, context: AnalysisContext): Promise<Partial<ErrorAnalysisReport>> {
    const classification = await this.classifyError(failure);
    return { classification };
  }
}

// Pros: Highly extensible, testable components, flexible deployment
// Cons: More complex initial setup, dependency management
```

#### 1.4 Testing Strategy for Step 1

**Unit Tests:**
```typescript
// tests/unit/core/interfaces.test.ts
describe('Core Interfaces', () => {
  describe('TestFailure Interface', () => {
    it('should validate complete TestFailure structure', () => {
      const testFailure: TestFailure = {
        id: 'test-failure-001',
        type: 'runtime',
        message: 'ReferenceError: variable is not defined',
        stackTrace: 'ReferenceError: variable is not defined\n    at test.js:10:5',
        testFile: './tests/example.test.js',
        lineNumber: 10,
        columnNumber: 5,
        context: {
          testName: 'should handle undefined variables',
          testSuite: 'Variable Handling Tests',
          framework: 'jest',
          environment: 'development',
          dependencies: ['jest', 'babel'],
          configuration: {}
        },
        timestamp: '2025-08-21T12:00:00.000Z',
        severity: 'high',
        metadata: {
          testRunner: 'jest',
          testFramework: 'jest',
          nodeVersion: '18.0.0',
          operatingSystem: 'darwin'
        }
      };

      expect(testFailure).toHaveProperty('id');
      expect(testFailure.type).toMatch(/^(syntax|runtime|assertion|timeout|network|configuration)$/);
      expect(testFailure.severity).toMatch(/^(critical|high|medium|low)$/);
      expect(testFailure.context.framework).toMatch(/^(jest|mocha|cypress|playwright|vitest|other)$/);
    });

    it('should require essential fields', () => {
      const incompleteFailure = {
        type: 'runtime',
        message: 'Error message'
        // Missing required fields
      };

      expect(() => validateTestFailure(incompleteFailure as TestFailure))
        .toThrow('Missing required fields: id, stackTrace, testFile');
    });
  });

  describe('ErrorClassification Interface', () => {
    it('should validate classification categories', () => {
      const validCategories = ['logic', 'environment', 'race-condition', 'ui', 'network', 'configuration'];
      const classification: ErrorClassification = {
        category: 'logic',
        subCategory: 'undefined-variable',
        severity: 'high',
        confidence: 0.92,
        rootCause: 'Variable accessed before declaration',
        requiredExpertise: 'intermediate',
        tags: ['javascript', 'scope', 'hoisting'],
        reasoning: 'Variable is accessed on line 10 but declared on line 15'
      };

      expect(validCategories).toContain(classification.category);
      expect(classification.confidence).toBeGreaterThanOrEqual(0);
      expect(classification.confidence).toBeLessThanOrEqual(1);
    });
  });
});
```

**Integration Tests:**
```typescript
// tests/integration/project-structure.test.ts
describe('Project Structure Integration', () => {
  it('should have all required directories', async () => {
    const requiredDirs = [
      './src/core',
      './src/services',
      './src/components',
      './src/utils',
      './src/cli',
      './tests/unit',
      './tests/integration',
      './tests/fixtures',
      './docs'
    ];

    for (const dir of requiredDirs) {
      expect(await fs.pathExists(dir)).toBe(true);
    }
  });

  it('should have valid TypeScript configuration', async () => {
    const tsconfigPath = './tsconfig.json';
    expect(await fs.pathExists(tsconfigPath)).toBe(true);

    const tsconfig = await fs.readJSON(tsconfigPath);
    expect(tsconfig.compilerOptions).toBeDefined();
    expect(tsconfig.compilerOptions.strict).toBe(true);
    expect(tsconfig.compilerOptions.target).toBe('ES2020');
  });

  it('should have correct package.json dependencies', async () => {
    const packageJson = await fs.readJSON('./package.json');
    
    const requiredDeps = [
      '@juspay/neurolink',
      'typescript',
      'puppeteer',
      'cheerio',
      'googleapis'
    ];

    requiredDeps.forEach(dep => {
      expect(packageJson.dependencies[dep] || packageJson.devDependencies[dep]).toBeDefined();
    });
  });
});
```

**âœ… Step 1 Completion Criteria:**
- [ ] All directory structures created and validated
- [ ] Core interfaces defined with comprehensive TypeScript types
- [ ] Interface validation functions implemented and tested
- [ ] Unit tests achieving 100% coverage for interfaces
- [ ] Integration tests validating project structure
- [ ] TypeScript compilation successful with strict mode
- [ ] ESLint configuration passing without warnings
- [ ] Documentation for core interfaces complete

---

### Step 2: Neurolink SDK Integration & Abstraction
**â±ï¸ Duration**: Day 1 (Afternoon - 4 hours)  
**Priority**: Critical - Foundation for AI-powered analysis

#### ğŸ¯ Step 2 Goals
- **Primary Goal**: Create reliable AI service abstraction with multi-provider support
- **Secondary Goal**: Implement robust error handling and retry mechanisms
- **Tertiary Goal**: Establish caching and rate limiting for optimal performance

#### ğŸ“‹ Success Criteria
- Neurolink service operational with error handling
- Multi-provider configuration working
- Caching and rate limiting mechanisms functional
- Integration tests validating real API communication

#### 2.1 Neurolink Service Implementation

**Core Neurolink Service:**
```typescript
// src/services/neurolink/NeuroLinkService.ts
import { NeuroLink } from '@juspay/neurolink';

export interface NeuroLinkConfig {
  providers: ProviderConfig[];
  enableAnalytics: boolean;
  enableEvaluation: boolean;
  timeout: number; // milliseconds
  retryAttempts: number;
  retryDelay: number; // milliseconds
  rateLimit: RateLimitConfig;
  cache: CacheConfig;
}

export interface ProviderConfig {
  name: string;
  endpoint?: string;
  apiKey?: string;
  model?: string;
  priority: number; // 1 = highest priority
  enabled: boolean;
  maxTokens?: number;
  temperature?: number;
}

export interface AIAnalysisRequest {
  prompt: string;
  context: AnalysisContext;
  provider?: string;
  temperature?: number;
  maxTokens?: number;
  timeout?: number;
  cache?: boolean;
}

export interface AIAnalysisResponse {
  content: string;
  provider: string;
  model: string;
  confidence: number; // 0-1
  usage: UsageMetrics;
  metadata: ResponseMetadata;
  cached: boolean;
}

export interface UsageMetrics {
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  cost: number; // USD
}

export interface ResponseMetadata {
  responseTime: number; // milliseconds
  retryAttempts: number;
  rateLimitRemaining?: number;
  requestId: string;
  timestamp: string;
}

export class NeuroLinkService {
  private neurolink: NeuroLink;
  private config: NeuroLinkConfig;
  private cache: Map<string, CachedResponse> = new Map();
  private rateLimiter: RateLimiter;
  private metrics: ServiceMetrics;

  constructor(config: NeuroLinkConfig) {
    this.config = config;
    this.neurolink = new NeuroLink({
      providers: config.providers.map(p => p.name),
      enableAnalytics: config.enableAnalytics,
      enableEvaluation: config.enableEvaluation
    });
    this.rateLimiter = new RateLimiter(config.rateLimit);
    this.metrics = new ServiceMetrics();
  }

  async analyze(request: AIAnalysisRequest): Promise<AIAnalysisResponse> {
    const requestId = this.generateRequestId();
    const startTime = Date.now();

    try {
      // Check cache first
      if (request.cache !== false) {
        const cached = await this.getCachedResponse(request);
        if (cached) {
          this.metrics.recordCacheHit();
          return { ...cached, cached: true };
        }
      }

      // Apply rate limiting
      await this.rateLimiter.waitForSlot();

      // Execute analysis with retry logic
      const response = await this.executeWithRetry(request, requestId);
      
      // Cache successful responses
      if (request.cache !== false && response.confidence > 0.7) {
        await this.cacheResponse(request, response);
      }

      this.metrics.recordSuccess(Date.now() - startTime);
      return { ...response, cached: false };

    } catch (error) {
      this.metrics.recordError(error);
      throw new NeuroLinkAnalysisError(
        `Analysis failed for request ${requestId}: ${error.message}`,
        error,
        { requestId, request }
      );
    }
  }

  async multiProviderAnalysis(request: AIAnalysisRequest): Promise<AIAnalysisResponse[]> {
    const enabledProviders = this.config.providers
      .filter(p => p.enabled)
      .sort((a, b) => a.priority - b.priority);

    const promises = enabledProviders.map(provider => 
      this.analyze({ 
        ...request, 
        provider: provider.name,
        timeout: request.timeout || provider.timeout 
      }).catch(error => ({
        error,
        provider: provider.name,
        failed: true
      }))
    );

    const results = await Promise.allSettled(promises);
    
    return results
      .filter(result => result.status === 'fulfilled' && !('failed' in result.value))
      .map(result => result.value as AIAnalysisResponse);
  }

  private async executeWithRetry(
    request: AIAnalysisRequest, 
    requestId: string
  ): Promise<AIAnalysisResponse> {
    let lastError: Error;
    
    for (let attempt = 1; attempt <= this.config.retryAttempts; attempt++) {
      try {
        const response = await this.neurolink.generate({
          input: { text: request.prompt },
          context: request.context,
          provider: request.provider,
          temperature: request.temperature || 0.3,
          maxTokens: request.maxTokens || 2000,
          timeout: request.timeout || this.config.timeout
        });

        return {
          content: response.content || response.text || '',
          provider: response.provider || request.provider || 'unknown',
          model: response.model || 'unknown',
          confidence: this.calculateConfidence(response),
          usage: {
            promptTokens: response.usage?.promptTokens || 0,
            completionTokens: response.usage?.completionTokens || 0,
            totalTokens: response.usage?.totalTokens || 0,
            cost: response.usage?.cost || 0
          },
          metadata: {
            responseTime: response.responseTime || 0,
            retryAttempts: attempt - 1,
            rateLimitRemaining: response.rateLimitRemaining,
            requestId,
            timestamp: new Date().toISOString()
          },
          cached: false
        };

      } catch (error) {
        lastError = error;
        
        if (attempt < this.config.retryAttempts) {
          await this.delay(this.config.retryDelay * attempt);
        }
      }
    }

    throw lastError!;
  }

  private calculateConfidence(response: any): number {
    // Calculate confidence based on response quality indicators
    let confidence = 0.5; // Base confidence

    // Check for structured response
    if (this.isValidJSON(response.content)) {
      confidence += 0.2;
    }

    // Check response length (too short or too long indicates low quality)
    const contentLength = response.content?.length || 0;
    if (contentLength > 100 && contentLength < 5000) {
      confidence += 0.1;
    } else if (contentLength < 50) {
      confidence -= 0.2;
    }

    // Check for specific quality indicators
    if (response.content?.includes('```')) {
      confidence += 0.1; // Contains code examples
    }

    if (response.usage?.totalTokens > 0) {
      confidence += 0.1; // Valid token usage
    }

    return Math.max(0, Math.min(1, confidence));
  }

  private isValidJSON(content: string): boolean {
    try {
      JSON.parse(content);
      return true;
    } catch {
      return false;
    }
  }

  private async getCachedResponse(request: AIAnalysisRequest): Promise<AIAnalysisResponse | null> {
    const cacheKey = this.generateCacheKey(request);
    const cached = this.cache.get(cacheKey);
    
    if (cached && !this.isCacheExpired(cached)) {
      return cached.response;
    }
    
    return null;
  }

  private async cacheResponse(request: AIAnalysisRequest, response: AIAnalysisResponse): Promise<void> {
    if (this.cache.size >= this.config.cache.maxSize) {
      this.evictOldestCacheEntries();
    }

    const cacheKey = this.generateCacheKey(request);
    this.cache.set(cacheKey, {
      response,
      timestamp: Date.now(),
      expiresAt: Date.now() + this.config.cache.ttl
    });
  }

  private generateCacheKey(request: AIAnalysisRequest): string {
    const keyData = {
      prompt: request.prompt,
      context: request.context,
      provider: request.provider
    };
    return Buffer.from(JSON.stringify(keyData)).toString('base64');
  }

  private generateRequestId(): string {
    return `nlreq_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

#### 2.2 Provider Management & Configuration

**Provider Manager Implementation:**
```typescript
// src/services/neurolink/ProviderManager.ts
export class ProviderManager {
  private providers: Map<string, ProviderConfig> = new Map();
  private healthStatus: Map<string, ProviderHealth> = new Map();
  private lastHealthCheck: Map<string, number> = new Map();

  constructor(private config: NeuroLinkConfig) {
    this.initializeProviders();
    this.startHealthMonitoring();
  }

  private initializeProviders(): void {
    this.config.providers.forEach(provider => {
      this.providers.set(provider.name, provider);
      this.healthStatus.set(provider.name, {
        status: 'unknown',
        responseTime: 0,
        errorRate: 0,
        lastError: null
      });
    });
  }

  getHealthyProviders(): ProviderConfig[] {
    return Array.from(this.providers.values())
      .filter(provider => {
        const health = this.healthStatus.get(provider.name);
        return provider.enabled && health?.status === 'healthy';
      })
      .sort((a, b) => a.priority - b.priority);
  }

  async selectOptimalProvider(
    request: AIAnalysisRequest
  ): Promise<ProviderConfig | null> {
    const healthyProviders = this.getHealthyProviders();
    
    if (healthyProviders.length === 0) {
      throw new Error('No healthy providers available');
    }

    // If specific provider requested, use it if healthy
    if (request.provider) {
      const requested = healthyProviders.find(p => p.name === request.provider);
      if (requested) return requested;
    }

    // Otherwise, select based on priority and performance
    return healthyProviders[0];
  }

  private startHealthMonitoring(): void {
    setInterval(() => {
      this.checkProvidersHealth();
    }, 60000); // Check every minute
  }

  private async checkProvidersHealth(): Promise<void> {
    const checkPromises = Array.from(this.providers.values()).map(provider => 
      this.checkProviderHealth(provider)
    );
    
    await Promise.allSettled(checkPromises);
  }

  private async checkProviderHealth(provider: ProviderConfig): Promise<void> {
    const startTime = Date.now();
    
    try {
      // Simple health check request
      await this.neurolink.generate({
        input: { text: 'health check' },
        provider: provider.name,
        maxTokens: 10,
        timeout: 5000
      });

      const responseTime = Date.now() - startTime;
      
      this.healthStatus.set(provider.name, {
        status: 'healthy',
        responseTime,
        errorRate: this.calculateErrorRate(provider.name),
        lastError: null
      });

    } catch (error) {
      this.healthStatus.set(provider.name, {
        status: 'unhealthy',
        responseTime: Date.now() - startTime,
        errorRate: this.calculateErrorRate(provider.name),
        lastError: error.message
      });
    }

    this.lastHealthCheck.set(provider.name, Date.now());
  }
}

interface ProviderHealth {
  status: 'healthy' | 'unhealthy' | 'unknown';
  responseTime: number;
  errorRate: number;
  lastError: string | null;
}

interface CachedResponse {
  response: AIAnalysisResponse;
  timestamp: number;
  expiresAt: number;
}

interface RateLimitConfig {
  requestsPerMinute: number;
  requestsPerHour: number;
  burstLimit: number;
}

interface CacheConfig {
  enabled: boolean;
  ttl: number; // Time to live in milliseconds
  maxSize: number; // Maximum number of cached responses
}
```

#### 2.3 Testing Strategy for Step 2

**Unit Tests for NeuroLinkService:**
```typescript
// tests/unit/services/neurolink/NeuroLinkService.test.ts
describe('NeuroLinkService', () => {
  let service: NeuroLinkService;
  let mockNeuroLink: jest.Mocked<NeuroLink>;
  let config: NeuroLinkConfig;

  beforeEach(() => {
    config = {
      providers: [
        {
          name: 'openai',
          model: 'gpt-4o',
          priority: 1,
          enabled: true,
          maxTokens: 2000,
          temperature: 0.3
        },
        {
          name: 'anthropic',
          model: 'claude-3-5-sonnet',
          priority: 2,
          enabled: true,
          maxTokens: 2000,
          temperature: 0.3
        }
      ],
      enableAnalytics: true,
      enableEvaluation: true,
      timeout: 30000,
      retryAttempts: 3,
      retryDelay: 1000,
      rateLimit: {
        requestsPerMinute: 60,
        requestsPerHour: 1000,
        burstLimit: 10
      },
      cache: {
        enabled: true,
        ttl: 3600000, // 1 hour
        maxSize: 1000
      }
    };

    mockNeuroLink = {
      generate: jest.fn()
    } as any;

    service = new NeuroLinkService(config);
    (service as any).neurolink = mockNeuroLink;
  });

  describe('analyze', () => {
    it('should successfully analyze error with valid response', async () => {
      const mockResponse = {
        content: 'This is a ReferenceError caused by accessing undefined variable',
        provider: 'openai',
        model: 'gpt-4o',
        usage: {
          promptTokens: 100,
          completionTokens: 50,
          totalTokens: 150,
          cost: 0.001
        },
        responseTime: 1500
      };

      mockNeuroLink.generate.mockResolvedValue(mockResponse);

      const request: AIAnalysisRequest = {
        prompt: 'Analyze this error: ReferenceError: x is not defined',
        context: {
          errorType: 'runtime',
          framework: 'jest'
        }
      };

      const result = await service.analyze(request);

      expect(result).toHaveProperty('content', mockResponse.content);
      expect(result).toHaveProperty('provider', 'openai');
      expect(result).toHaveProperty('cached', false);
      expect(result.confidence).toBeGreaterThan(0);
      expect(result.confidence).toBeLessThanOrEqual(1);
    });

    it('should handle provider failures with retry logic', async () => {
      mockNeuroLink.generate
        .mockRejectedValueOnce(new Error('Rate limit exceeded'))
        .mockRejectedValueOnce(new Error('Temporary server error'))
        .mockResolvedValueOnce({
          content: 'Analysis result after retries',
          provider: 'openai',
          usage: { totalTokens: 100 }
        });

      const request: AIAnalysisRequest = {
        prompt: 'Analyze this error',
        context: { errorType: 'runtime' }
      };

      const result = await service.analyze(request);

      expect(result.content).toBe('Analysis result after retries');
      expect(result.metadata.retryAttempts).toBe(2);
      expect(mockNeuroLink.generate).toHaveBeenCalledTimes(3);
    });

    it('should use cached responses when available', async () => {
      const request: AIAnalysisRequest = {
        prompt: 'Analyze this error',
        context: { errorType: 'runtime' },
        cache: true
      };

      // First call - should cache the response
      mockNeuroLink.generate.mockResolvedValueOnce({
        content: 'Cached analysis',
        provider: 'openai',
        usage: { totalTokens: 100 }
      });

      const firstResult = await service.analyze(request);
      expect(firstResult.cached).toBe(false);

      // Second call - should use cache
      const secondResult = await service.analyze(request);
      expect(secondResult.cached).toBe(true);
      expect(secondResult.content).toBe('Cached analysis');
      expect(mockNeuroLink.generate).toHaveBeenCalledTimes(1);
    });

    it('should respect cache disable setting', async () => {
      const request: AIAnalysisRequest = {
        prompt: 'Analyze this error',
        context: { errorType: 'runtime' },
        cache: false
      };

      mockNeuroLink.generate.mockResolvedValue({
        content: 'Fresh analysis',
        provider: 'openai',
        usage: { totalTokens: 100 }
      });

      await service.analyze(request);
      await service.analyze(request);

      expect(mockNeuroLink.generate).toHaveBeenCalledTimes(2);
    });
  });

  describe('multiProviderAnalysis', () => {
    it('should get responses from multiple providers', async () => {
      mockNeuroLink.generate
        .mockResolvedValueOnce({
          content: 'OpenAI analysis',
          provider: 'openai',
          usage: { totalTokens: 100 }
        })
        .mockResolvedValueOnce({
          content: 'Anthropic analysis',
          provider: 'anthropic',
          usage: { totalTokens: 120 }
        });

      const request: AIAnalysisRequest = {
        prompt: 'Analyze this error',
        context: { errorType: 'runtime' }
      };

      const results = await service.multiProviderAnalysis(request);

      expect(results).toHaveLength(2);
      expect(results[0].provider).toBe('openai');
      expect(results[1].provider).toBe('anthropic');
    });

    it('should handle partial provider failures gracefully', async () => {
      mockNeuroLink.generate
        .mockResolvedValueOnce({
          content: 'OpenAI analysis',
          provider: 'openai',
          usage: { totalTokens: 100 }
        })
        .mockRejectedValueOnce(new Error('Anthropic failed'));

      const request: AIAnalysisRequest = {
        prompt: 'Analyze this error',
        context: { errorType: 'runtime' }
      };

      const results = await service.multiProviderAnalysis(request);

      expect(results).toHaveLength(1);
      expect(results[0].provider).toBe('openai');
    });
  });

  describe('confidence calculation', () => {
    it('should calculate higher confidence for structured responses', () => {
      const service = new NeuroLinkService(config);
      
      const structuredResponse = {
        content: '{"analysis": "This is structured", "confidence": 0.9}'
      };
      
      const unstructuredResponse = {
        content: 'This is just plain text without structure'
      };

      const structuredConfidence = (service as any).calculateConfidence(structuredResponse);
      const unstructuredConfidence = (service as any).calculateConfidence(unstructuredResponse);

      expect(structuredConfidence).toBeGreaterThan(unstructuredConfidence);
    });

    it('should penalize very short responses', () => {
      const service = new NeuroLinkService(config);
      
      const shortResponse = { content: 'Error' };
      const adequateResponse = { content: 'This is a ReferenceError caused by accessing an undefined variable in the test scope.' };

      const shortConfidence = (service as any).calculateConfidence(shortResponse);
      const adequateConfidence = (service as any).calculateConfidence(adequateResponse);

      expect(adequateConfidence).toBeGreaterThan(shortConfidence);
    });
  });
});
```

**Integration Tests:**
```typescript
// tests/integration/services/neurolink-integration.test.ts
describe('NeuroLink Integration', () => {
  let service: NeuroLinkService;

  beforeAll(() => {
    // This test requires actual Neurolink configuration
    if (!process.env.NEUROLINK_API_KEY) {
      pending('Neurolink API key not configured');
    }

    service = new NeuroLinkService({
      providers: [
        {
          name: 'openai',
          apiKey: process.env.OPENAI_API_KEY,
          model: 'gpt-4o-mini',
          priority: 1,
          enabled: true
        }
      ],
      enableAnalytics: false,
      enableEvaluation: false,
      timeout: 30000,
      retryAttempts: 2,
      retryDelay: 1000,
      rateLimit: {
        requestsPerMinute: 10,
        requestsPerHour: 100,
        burstLimit: 5
      },
      cache: {
        enabled: false,
        ttl: 0,
        maxSize: 0
      }
    });
  });

  it('should successfully analyze real error', async () => {
    const request: AIAnalysisRequest = {
      prompt: `Analyze this JavaScript test error:
      
      ReferenceError: userName is not defined
      at UserProfile.test.js:15:23
      at Object.<anonymous> (UserProfile.test.js:10:5)
      
      Test code context:
      describe('UserProfile', () => {
        it('should display user name', () => {
          const wrapper = shallow(<UserProfile />);
          expect(wrapper.find('.username').text()).toBe(userName);
        });
      });
      
      Please provide analysis of the root cause and suggest fixes.`,
      context: {
        errorType: 'runtime',
        framework: 'jest',
        testType: 'unit'
      }
    };

    const result = await service.analyze(request);

    expect(result.content).toBeDefined();
    expect(result.content.length).toBeGreaterThan(50);
    expect(result.provider).toBe('openai');
    expect(result.confidence).toBeGreaterThan(0);
    expect(result.usage.totalTokens).toBeGreaterThan(0);
  }, 30000);

  it('should handle rate limiting gracefully', async () => {
    const requests = Array(15).fill(null).map((_, i) => ({
      prompt: `Simple analysis request ${i}`,
      context: { errorType: 'test' }
    }));

    const startTime = Date.now();
    const results = await Promise.allSettled(
      requests.map(req => service.analyze(req))
    );
    const endTime = Date.now();

    const successful = results.filter(r => r.status === 'fulfilled').length;
    const failed = results.filter(r => r.status === 'rejected').length;

    expect(successful).toBeGreaterThan(0);
    
    // Should take some time due to rate limiting
    expect(endTime - startTime).toBeGreaterThan(5000);
    
    console.log(`Rate limiting test: ${successful} successful, ${failed} failed`);
  }, 60000);
});
```

**âœ… Step 2 Completion Criteria:**
- [ ] NeuroLinkService implementation complete with error handling
- [ ] Provider management and health monitoring implemented
- [ ] Caching and rate limiting mechanisms working
- [ ] Unit tests achieving 95% coverage for NeuroLinkService
- [ ] Integration tests validating real Neurolink API communication
- [ ] Performance benchmarks meeting targets (<2s average response time)
- [ ] Error handling covering all failure scenarios
- [ ] Documentation for service configuration and usage

---

### Step 3: Error Classification Engine
**â±ï¸ Duration**: Day 2 (Morning - 4 hours)  
**Priority**: High - Core intelligence for error categorization

#### ğŸ¯ Step 3 Goals
- **Primary Goal**: Build accurate multi-AI error classification system
- **Secondary Goal**: Implement pattern learning and recognition capabilities
- **Tertiary Goal**: Create confidence scoring for classification reliability

#### ğŸ“‹ Success Criteria
- Error classification with >85% accuracy
- Multi-AI consensus mechanism working
- Pattern database with learning capabilities
- Classification confidence scoring operational

#### 3.1 Multi-AI Error Classification System

**Error Classification Engine Implementation:**
```typescript
// src/components/analyzer/ErrorClassificationEngine.ts
export class ErrorClassificationEngine {
  constructor(
    private neurolinkService: NeuroLinkService,
    private patternDatabase: ErrorPatternDatabase,
    private config: ClassificationConfig
  ) {}

  async classifyError(failure: TestFailure): Promise<ErrorClassification> {
    try {
      // 1. Quick pattern-based classification
      const patternMatch = await this.tryPatternMatching(failure);
      
      // 2. AI-powered classification with multiple providers
      const aiClassifications = await this.performAIClassification(failure);
      
      // 3. Consolidate results using confidence weighting
      const consolidatedClassification = this.consolidateClassifications(
        patternMatch, 
        aiClassifications
      );
      
      // 4. Validate and enhance classification
      const finalClassification = await this.validateAndEnhance(
        consolidatedClassification, 
        failure
      );

      // 5. Learn from this classification for future improvements
      await this.updatePatternDatabase(failure, finalClassification);

      return finalClassification;

    } catch (error) {
      throw new ClassificationError(
        `Failed to classify error: ${error.message}`,
        error,
        { failure }
      );
    }
  }

  private async tryPatternMatching(failure: TestFailure): Promise<Partial<ErrorClassification>> {
    const patterns = await this.patternDatabase.findMatchingPatterns(failure);
    
    if (patterns.length === 0) {
      return { confidence: 0.1 };
    }

    // Find best matching pattern
    const bestMatch = patterns.reduce((best, current) => 
      current.confidence > best.confidence ? current : best
    );

    return {
      category: bestMatch.category,
      subCategory: bestMatch.subCategory,
      severity: bestMatch.severity,
      confidence: Math.min(0.7, bestMatch.confidence), // Cap pattern confidence
      tags: bestMatch.tags,
      reasoning: `Pattern match: ${bestMatch.description}`
    };
  }

  private async performAIClassification(failure: TestFailure): Promise<ErrorClassification[]> {
    const classificationPrompt = this.buildClassificationPrompt(failure);
    
    // Get classifications from multiple AI providers
    const aiResponses = await this.neurolinkService.multiProviderAnalysis({
      prompt: classificationPrompt,
      context: {
        taskType: 'error-classification',
        errorType: failure.type,
        framework: failure.context.framework
      },
      temperature: 0.1, // Low temperature for consistent classification
      maxTokens: 1000
    });

    return aiResponses.map(response => this.parseClassificationResponse(response));
  }

  private buildClassificationPrompt(failure: TestFailure): string {
    return `Classify this test failure with high precision:

ERROR DETAILS:
- Type: ${failure.type}
- Message: ${failure.message}
- Stack Trace: ${failure.stackTrace}
- Test Framework: ${failure.context.framework}
- Test Name: ${failure.context.testName}
- Environment: ${failure.context.environment}

CLASSIFICATION CATEGORIES:
1. LOGIC ERRORS
   - undefined-variable: Variables accessed before declaration
   - type-mismatch: Incorrect data types or type coercion issues
   - algorithm-error: Faulty business logic or computational errors
   - validation-failure: Input validation or data format issues

2. ENVIRONMENT ISSUES  
   - dependency-missing: Missing or incorrect dependencies
   - configuration-error: Wrong environment configuration
   - version-conflict: Dependency version incompatibilities
   - setup-failure: Test environment setup problems

3. RACE CONDITIONS
   - async-timing: Async/await timing issues
   - promise-chain: Promise resolution/rejection problems  
   - callback-timing: Callback execution timing issues
   - state-mutation: Shared state modification conflicts

4. UI/INTERACTION ISSUES
   - element-not-found: DOM elements missing or not rendered
   - event-handling: Event listeners or handlers not working
   - rendering-issue: Component rendering or lifecycle problems
   - state-management: UI state management failures

5. NETWORK/API ISSUES
   - http-request: HTTP request failures or timeouts
   - data-format: API response format mismatches
   - connectivity: Network connectivity problems
   - authentication: Auth token or permission issues

6. CONFIGURATION ISSUES
   - build-config: Build tool configuration problems
   - test-config: Test runner or framework configuration
   - path-resolution: File path or module resolution issues
   - environment-variable: Missing or incorrect env vars

REQUIRED OUTPUT FORMAT (JSON):
{
  "category": "one of the 6 main categories",
  "subCategory": "specific subcategory from above list",
  "severity": "critical|high|medium|low",
  "confidence": 0.XX, // 0-1 confidence score
  "rootCause": "concise root cause explanation",
  "requiredExpertise": "beginner|intermediate|advanced",
  "tags": ["relevant", "tags", "for", "searching"],
  "reasoning": "detailed explanation of classification logic"
}

SEVERITY GUIDELINES:
- critical: Prevents all tests from running
- high: Breaks core functionality or blocks development
- medium: Affects specific features but has workarounds
- low: Minor issues with minimal impact

Provide only the JSON response, no additional text.`;
  }

  private parseClassificationResponse(response: AIAnalysisResponse): ErrorClassification {
    try {
      const parsed = JSON.parse(response.content);
      
      // Validate required fields
      this.validateClassificationStructure(parsed);
      
      // Apply response confidence weighting
      const adjustedConfidence = parsed.confidence * response.confidence;
      
      return {
        ...parsed,
        confidence: adjustedConfidence,
        aiProvider: response.provider,
        responseMetadata: {
          originalConfidence: parsed.confidence,
          providerConfidence: response.confidence,
          responseTime: response.metadata.responseTime
        }
      };

    } catch (error) {
      throw new ClassificationParseError(
        `Failed to parse classification response from ${response.provider}`,
        error,
        { response }
      );
    }
  }

  private consolidateClassifications(
    patternMatch: Partial<ErrorClassification>,
    aiClassifications: ErrorClassification[]
  ): ErrorClassification {
    
    if (aiClassifications.length === 0) {
      throw new Error('No AI classifications received');
    }

    // Weight classifications by confidence
    const allClassifications = [
      ...(patternMatch.confidence > 0.3 ? [patternMatch as ErrorClassification] : []),
      ...aiClassifications
    ];

    // Group by category and find consensus
    const categoryVotes = this.groupClassificationsByCategory(allClassifications);
    const winningCategory = this.findCategoryConsensus(categoryVotes);
    
    // Get best classification from winning category
    const categoryClassifications = allClassifications.filter(
      c => c.category === winningCategory
    );
    
    const bestClassification = categoryClassifications.reduce((best, current) => 
      current.confidence > best.confidence ? current : best
    );

    // Calculate consensus confidence
    const consensusConfidence = this.calculateConsensusConfidence(
      categoryClassifications, 
      allClassifications.length
    );

    return {
      ...bestClassification,
      confidence: consensusConfidence,
      consensusDetails: {
        totalClassifications: allClassifications.length,
        categoryAgreement: categoryClassifications.length / allClassifications.length,
        votingBreakdown: categoryVotes,
        sources: allClassifications.map(c => c.aiProvider || 'pattern-match')
      }
    };
  }

  private async validateAndEnhance(
    classification: ErrorClassification, 
    failure: TestFailure
  ): Promise<ErrorClassification> {
    
    // Validate classification makes sense for the error type
    const validationResult = await this.validateClassificationLogic(classification, failure);
    
    if (!validationResult.isValid) {
      // Attempt reclassification with additional context
      const enhancedPrompt = this.buildEnhancedClassificationPrompt(failure, validationResult.issues);
      
      const fallbackResponse = await this.neurolinkService.analyze({
        prompt: enhancedPrompt,
        context: {
          taskType: 'error-reclassification',
          previousIssues: validationResult.issues
        }
      });

      const fallbackClassification = this.parseClassificationResponse(fallbackResponse);
      
      // Use fallback if it's more confident
      if (fallbackClassification.confidence > classification.confidence) {
        return { ...fallbackClassification, reasoning: `Reclassified due to validation issues: ${validationResult.issues.join(', ')}` };
      }
    }

    // Enhance with additional context
    return {
      ...classification,
      enhancedContext: {
        frameworkSpecific: await this.getFrameworkSpecificInsights(classification, failure),
        similarPatterns: await this.findSimilarHistoricalPatterns(classification, failure),
        communityFrequency: await this.getCommunityErrorFrequency(classification)
      }
    };
  }

  private async updatePatternDatabase(
    failure: TestFailure, 
    classification: ErrorClassification
  ): Promise<void> {
    if (classification.confidence > 0.8) {
      await this.patternDatabase.addPattern({
        errorSignature: this.generateErrorSignature(failure),
        classification: classification,
        timestamp: new Date(),
        source: 'ai-classification',
        validatedBy: null
      });
    }
  }
}
```

#### 3.2 Pattern Database and Learning System

**Error Pattern Database Implementation:**
```typescript
// src/storage/ErrorPatternDatabase.ts
export interface ErrorPattern {
  id: string;
  errorSignature: ErrorSignature;
  classification: ErrorClassification;
  occurrenceCount: number;
  lastSeen: Date;
  confidence: number;
  source: 'manual' | 'ai-classification' | 'validated-fix';
  validatedBy?: string;
  tags: string[];
  relatedPatterns: string[];
}

export interface ErrorSignature {
  messagePattern: string;
  stackTracePattern: string;
  frameworkContext: string;
  errorTypePattern: string;
  filePathPattern?: string;
}

export class ErrorPatternDatabase {
  constructor(
    private storage: DatabaseStorage,
    private config: PatternDatabaseConfig
  ) {}

  async findMatchingPatterns(failure: TestFailure): Promise<ErrorPattern[]> {
    const signature = this.generateErrorSignature(failure);
    
    // 1. Exact signature match
    const exactMatches = await this.storage.query(`
      SELECT * FROM error_patterns 
      WHERE error_signature = ? 
      ORDER BY confidence DESC, occurrence_count DESC
    `, [JSON.stringify(signature)]);

    if (exactMatches.length > 0) {
      return exactMatches.map(row => this.deserializePattern(row));
    }

    // 2. Fuzzy pattern matching
    const fuzzyMatches = await this.performFuzzyMatching(signature);
    
    // 3. Message pattern matching using regex
    const regexMatches = await this.performRegexMatching(failure);

    // Combine and rank all matches
    return this.rankPatternMatches([...fuzzyMatches, ...regexMatches], signature);
  }

  private async performFuzzyMatching(signature: ErrorSignature): Promise<ErrorPattern[]> {
    const allPatterns = await this.storage.query(`
      SELECT * FROM error_patterns 
      WHERE framework_context = ? 
      ORDER BY confidence DESC
    `, [signature.frameworkContext]);

    return allPatterns
      .map(row => {
        const pattern = this.deserializePattern(row);
        const similarity = this.calculateSignatureSimilarity(signature, pattern.errorSignature);
        return { ...pattern, matchSimilarity: similarity };
      })
      .filter(pattern => pattern.matchSimilarity > 0.7)
      .sort((a, b) => b.matchSimilarity - a.matchSimilarity);
  }

  private calculateSignatureSimilarity(sig1: ErrorSignature, sig2: ErrorSignature): number {
    // Calculate similarity score based on multiple factors
    let similarity = 0;
    let factors = 0;

    // Message pattern similarity (most important)
    if (sig1.messagePattern && sig2.messagePattern) {
      similarity += this.calculateStringSimilarity(sig1.messagePattern, sig2.messagePattern) * 0.4;
      factors += 0.4;
    }

    // Stack trace pattern similarity
    if (sig1.stackTracePattern && sig2.stackTracePattern) {
      similarity += this.calculateStringSimilarity(sig1.stackTracePattern, sig2.stackTracePattern) * 0.3;
      factors += 0.3;
    }

    // Framework context match
    if (sig1.frameworkContext === sig2.frameworkContext) {
      similarity += 0.2;
      factors += 0.2;
    }

    // Error type pattern match
    if (sig1.errorTypePattern === sig2.errorTypePattern) {
      similarity += 0.1;
      factors += 0.1;
    }

    return factors > 0 ? similarity / factors : 0;
  }

  private calculateStringSimilarity(str1: string, str2: string): number {
    // Levenshtein distance implementation for string similarity
    const len1 = str1.length;
    const len2 = str2.length;
    const matrix = Array(len2 + 1).fill(null).map(() => Array(len1 + 1).fill(null));

    for (let i = 0; i <= len1; i++) matrix[0][i] = i;
    for (let j = 0; j <= len2; j++) matrix[j][0] = j;

    for (let j = 1; j <= len2; j++) {
      for (let i = 1; i <= len1; i++) {
        const cost = str1[i - 1] === str2[j - 1] ? 0 : 1;
        matrix[j][i] = Math.min(
          matrix[j][i - 1] + 1,     // deletion
          matrix[j - 1][i] + 1,     // insertion
          matrix[j - 1][i - 1] + cost // substitution
        );
      }
    }

    const maxLen = Math.max(len1, len2);
    return maxLen === 0 ? 1 : (maxLen - matrix[len2][len1]) / maxLen;
  }

  async addPattern(pattern: Omit<ErrorPattern, 'id' | 'occurrenceCount' | 'lastSeen'>): Promise<string> {
    const id = this.generatePatternId(pattern);
    
    // Check if pattern already exists
    const existing = await this.storage.query(`
      SELECT * FROM error_patterns WHERE id = ?
    `, [id]);

    if (existing.length > 0) {
      // Update occurrence count and last seen
      await this.storage.execute(`
        UPDATE error_patterns 
        SET occurrence_count = occurrence_count + 1, 
            last_seen = ?, 
            confidence = ?
        WHERE id = ?
      `, [new Date().toISOString(), pattern.confidence, id]);
    } else {
      // Insert new pattern
      await this.storage.execute(`
        INSERT INTO error_patterns (
          id, error_signature, classification, occurrence_count, 
          last_seen, confidence, source, validated_by, tags, related_patterns
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
      `, [
        id,
        JSON.stringify(pattern.errorSignature),
        JSON.stringify(pattern.classification),
        1,
        new Date().toISOString(),
        pattern.confidence,
        pattern.source,
        pattern.validatedBy || null,
        JSON.stringify(pattern.tags || []),
        JSON.stringify(pattern.relatedPatterns || [])
      ]);
    }

    return id;
  }

  private generatePatternId(pattern: any): string {
    const signature = JSON.stringify(pattern.errorSignature);
    return Buffer.from(signature).toString('base64').substring(0, 12);
  }
}
```

#### 3.3 Testing Strategy for Step 3

**Unit Tests for Error Classification:**
```typescript
// tests/unit/components/analyzer/ErrorClassificationEngine.test.ts
describe('ErrorClassificationEngine', () => {
  let engine: ErrorClassificationEngine;
  let mockNeuroLink: jest.Mocked<NeuroLinkService>;
  let mockPatternDB: jest.Mocked<ErrorPatternDatabase>;

  beforeEach(() => {
    mockNeuroLink = {
      multiProviderAnalysis: jest.fn(),
      analyze: jest.fn()
    } as any;

    mockPatternDB = {
      findMatchingPatterns: jest.fn(),
      addPattern: jest.fn()
    } as any;

    engine = new ErrorClassificationEngine(
      mockNeuroLink,
      mockPatternDB,
      { enablePatternMatching: true, confidenceThreshold: 0.7 }
    );
  });

  describe('classifyError', () => {
    it('should successfully classify a runtime error', async () => {
      const testFailure: TestFailure = {
        id: 'test-001',
        type: 'runtime',
        message: 'ReferenceError: userName is not defined',
        stackTrace: 'ReferenceError: userName is not defined\n    at UserProfile.test.js:15:23',
        testFile: './tests/UserProfile.test.js',
        context: {
          testName: 'should display user name',
          testSuite: 'UserProfile Tests',
          framework: 'jest',
          environment: 'development',
          dependencies: ['react', 'enzyme'],
          configuration: {}
        },
        timestamp: '2025-08-22T06:00:00.000Z',
        severity: 'high',
        metadata: {
          testRunner: 'jest',
          testFramework: 'jest',
          operatingSystem: 'darwin'
        }
      };

      // Mock pattern matching (no matches)
      mockPatternDB.findMatchingPatterns.mockResolvedValue([]);

      // Mock AI classification responses
      mockNeuroLink.multiProviderAnalysis.mockResolvedValue([
        {
          content: JSON.stringify({
            category: 'logic',
            subCategory: 'undefined-variable',
            severity: 'high',
            confidence: 0.92,
            rootCause: 'Variable userName is referenced but not defined in scope',
            requiredExpertise: 'beginner',
            tags: ['javascript', 'reference-error', 'scope'],
            reasoning: 'The error indicates a variable is being accessed before it is declared or imported'
          }),
          provider: 'openai',
          model: 'gpt-4o',
          confidence: 0.95,
          usage: { totalTokens: 150 },
          metadata: { responseTime: 1200, retryAttempts: 0, requestId: 'req-001', timestamp: '' },
          cached: false
        }
      ]);

      const result = await engine.classifyError(testFailure);

      expect(result.category).toBe('logic');
      expect(result.subCategory).toBe('undefined-variable');
      expect(result.severity).toBe('high');
      expect(result.confidence).toBeGreaterThan(0.8);
      expect(result.tags).toContain('javascript');
      expect(mockPatternDB.addPattern).toHaveBeenCalled();
    });

    it('should use pattern matching when high-confidence patterns exist', async () => {
      const testFailure: TestFailure = {
        id: 'test-002',
        type: 'runtime',
        message: 'TypeError: Cannot read property "length" of undefined',
        stackTrace: 'TypeError: Cannot read property "length" of undefined\n    at utils.js:42:15',
        testFile: './tests/utils.test.js',
        context: {
          testName: 'should handle array operations',
          testSuite: 'Utils Tests',
          framework: 'jest',
          environment: 'development',
          dependencies: ['lodash'],
          configuration: {}
        },
        timestamp: '2025-08-22T06:00:00.000Z',
        severity: 'medium',
        metadata: {
          testRunner: 'jest',
          testFramework: 'jest',
          operatingSystem: 'darwin'
        }
      };

      // Mock high-confidence pattern match
      const existingPattern: ErrorPattern = {
        id: 'pattern-001',
        errorSignature: {
          messagePattern: 'Cannot read property.*of undefined',
          stackTracePattern: 'TypeError.*undefined',
          frameworkContext: 'jest',
          errorTypePattern: 'runtime'
        },
        classification: {
          category: 'logic',
          subCategory: 'null-undefined-access',
          severity: 'medium',
          confidence: 0.88,
          rootCause: 'Attempting to access property of null or undefined value',
          requiredExpertise: 'beginner',
          tags: ['javascript', 'null-check', 'defensive-programming'],
          reasoning: 'Pattern-based classification for undefined property access'
        },
        occurrenceCount: 15,
        lastSeen: new Date(),
        confidence: 0.88,
        source: 'validated-fix',
        tags: ['common-pattern'],
        relatedPatterns: []
      };

      mockPatternDB.findMatchingPatterns.mockResolvedValue([existingPattern]);

      // Should not call AI classification due to high-confidence pattern match
      mockNeuroLink.multiProviderAnalysis.mockResolvedValue([]);

      const result = await engine.classifyError(testFailure);

      expect(result.category).toBe('logic');
      expect(result.subCategory).toBe('null-undefined-access');
      expect(result.reasoning).toContain('Pattern match');
      expect(mockNeuroLink.multiProviderAnalysis).not.toHaveBeenCalled();
    });

    it('should handle multiple AI provider disagreement', async () => {
      const testFailure: TestFailure = {
        id: 'test-003',
        type: 'timeout',
        message: 'Test timeout exceeded: 5000ms',
        stackTrace: 'Error: Test timeout\n    at async-test.js:20:10',
        testFile: './tests/async.test.js',
        context: {
          testName: 'should handle async operations',
          testSuite: 'Async Tests',
          framework: 'jest',
          environment: 'development',
          dependencies: ['axios'],
          configuration: {}
        },
        timestamp: '2025-08-22T06:00:00.000Z',
        severity: 'medium',
        metadata: {
          testRunner: 'jest',
          testFramework: 'jest',
          operatingSystem: 'darwin'
        }
      };

      mockPatternDB.findMatchingPatterns.mockResolvedValue([]);

      // Mock different AI provider responses
      mockNeuroLink.multiProviderAnalysis.mockResolvedValue([
        {
          content: JSON.stringify({
            category: 'race-condition',
            subCategory: 'async-timing',
            severity: 'medium',
            confidence: 0.85,
            rootCause: 'Async operation taking longer than expected',
            requiredExpertise: 'intermediate',
            tags: ['async', 'timing', 'performance'],
            reasoning: 'Timeout indicates async timing issues'
          }),
          provider: 'openai',
          confidence: 0.9,
          usage: { totalTokens: 120 },
          metadata: { responseTime: 1100, retryAttempts: 0, requestId: 'req-002', timestamp: '' },
          cached: false
        } as AIAnalysisResponse,
        {
          content: JSON.stringify({
            category: 'configuration',
            subCategory: 'test-config',
            severity: 'low',
            confidence: 0.75,
            rootCause: 'Test timeout configuration too restrictive',
            requiredExpertise: 'beginner',
            tags: ['configuration', 'timeout', 'jest'],
            reasoning: 'Timeout error could be configuration issue'
          }),
          provider: 'anthropic',
          confidence: 0.8,
          usage: { totalTokens: 110 },
          metadata: { responseTime: 1300, retryAttempts: 0, requestId: 'req-003', timestamp: '' },
          cached: false
        } as AIAnalysisResponse
      ]);

      const result = await engine.classifyError(testFailure);

      // Should choose the higher confidence classification
      expect(result.category).toBe('race-condition');
      expect(result.subCategory).toBe('async-timing');
      expect(result.consensusDetails).toBeDefined();
      expect(result.consensusDetails.totalClassifications).toBe(2);
    });
  });

  describe('buildClassificationPrompt', () => {
    it('should build comprehensive classification prompt', () => {
      const testFailure: TestFailure = {
        id: 'test-prompt',
        type: 'assertion',
        message: 'Expected "Hello" but received "Hi"',
        stackTrace: 'AssertionError\n    at test.js:10',
        testFile: './test.js',
        context: {
          testName: 'greeting test',
          testSuite: 'Greeting Suite',
          framework: 'mocha',
          environment: 'ci',
          dependencies: ['chai'],
          configuration: {}
        },
        timestamp: '2025-08-22T06:00:00.000Z',
        severity: 'low',
        metadata: {
          testRunner: 'mocha',
          testFramework: 'mocha',
          operatingSystem: 'linux'
        }
      };

      const prompt = (engine as any).buildClassificationPrompt(testFailure);

      expect(prompt).toContain('assertion');
      expect(prompt).toContain('Expected "Hello" but received "Hi"');
      expect(prompt).toContain('mocha');
      expect(prompt).toContain('LOGIC ERRORS');
      expect(prompt).toContain('REQUIRED OUTPUT FORMAT (JSON)');
      expect(prompt).toContain('SEVERITY GUIDELINES');
    });
  });
});
```

**âœ… Step 3 Completion Criteria:**
- [ ] Error classification engine implemented with multi-AI consensus
- [ ] Pattern database with fuzzy matching and learning capabilities
- [ ] Classification prompt optimization for consistent results
- [ ] Unit tests achieving 90% coverage for classification logic
- [ ] Integration tests with real error patterns
- [ ] Performance benchmarks (<500ms for classification)
- [ ] Validation of classification accuracy against known error types
- [ ] Documentation for classification categories and confidence scoring

---

### Step 4: Code Context Analysis & Visual Analysis
**â±ï¸ Duration**: Day 2 (Afternoon - 4 hours)  
**Priority**: High - Contextual understanding for accurate suggestions

#### ğŸ¯ Step 4 Goals
- **Primary Goal**: Extract meaningful code context around test failures
- **Secondary Goal**: Implement visual analysis for UI-related errors
- **Tertiary Goal**: Create comprehensive failure environment analysis

#### ğŸ“‹ Success Criteria
- Code context extraction with AST parsing
- Visual analysis capturing DOM state and screenshots
- Performance metrics collection during analysis
- Integration with error classification for UI failures

#### 4.1 Code Context Analyzer Implementation

**Advanced Code Context Analysis:**
```typescript
// src/components/analyzer/CodeContextAnalyzer.ts
export class CodeContextAnalyzer {
  constructor(
    private astParser: ASTParser,
    private fileSystemReader: FileSystemReader,
    private dependencyAnalyzer: DependencyAnalyzer
  ) {}

  async analyzeCodeContext(failure: TestFailure): Promise<CodeContext> {
    try {
      // 1. Read and parse the failing test file
      const testFileContent = await this.fileSystemReader.readFile(failure.testFile);
      const testFileAST = await this.astParser.parse(testFileContent, 'typescript');

      // 2. Extract code around the failure point
      const surroundingCode = this.extractSurroundingCode(
        testFileContent, 
        failure.lineNumber || 1, 
        20 // lines of context
      );

      // 3. Analyze imports and dependencies
      const imports = await this.analyzeImports(testFileAST, failure.testFile);
      const dependencies = await this.dependencyAnalyzer.analyzeDependencies(failure.testFile);

      // 4. Extract functions and variables in scope
      const functions = this.extractFunctions(testFileAST, failure.lineNumber);
      const variables = this.extractVariables(testFileAST, failure.lineNumber);

      // 5. Analyze file structure and relationships
      const fileStructure = await this.analyzeFileStructure(failure.testFile);

      // 6. Get related source files if this is a test file
      const relatedSourceFiles = await this.findRelatedSourceFiles(failure.testFile);

      return {
        relevantCode: surroundingCode.code,
        surroundingLines: surroundingCode.lines,
        imports,
        functions,
        variables,
        dependencies,
        fileStructure,
        syntaxTree: testFileAST,
        relatedFiles: relatedSourceFiles,
        failureLocation: {
          line: failure.lineNumber || 1,
          column: failure.columnNumber || 1,
          context: surroundingCode.failureContext
        }
      };

    } catch (error) {
      throw new CodeContextError(
        `Failed to analyze code context: ${error.message}`,
        error,
        { failure }
      );
    }
  }

  private extractSurroundingCode(content: string, failureLine: number, contextLines: number) {
    const lines = content.split('\n');
    const startLine = Math.max(0, failureLine - contextLines - 1);
    const endLine = Math.min(lines.length, failureLine + contextLines);
    
    const surroundingLines: CodeLine[] = [];
    let relevantCode = '';

    for (let i = startLine; i < endLine; i++) {
      const isFailureLine = i === failureLine - 1;
      const line: CodeLine = {
        lineNumber: i + 1,
        content: lines[i] || '',
        isHighlighted: isFailureLine,
        annotation: isFailureLine ? 'FAILURE POINT' : undefined
      };
      
      surroundingLines.push(line);
      relevantCode += `${i + 1}: ${lines[i] || ''}\n`;
    }

    return {
      code: relevantCode,
      lines: surroundingLines,
      failureContext: {
        beforeFailure: lines.slice(Math.max(0, failureLine - 6), failureLine - 1),
        failureLine: lines[failureLine - 1] || '',
        afterFailure: lines.slice(failureLine, failureLine + 5)
      }
    };
  }

  private async analyzeImports(ast: ASTNode, filePath: string): Promise<ImportStatement[]> {
    const imports: ImportStatement[] = [];
    
    // Extract import statements from AST
    this.traverseAST(ast, (node) => {
      if (node.type === 'ImportDeclaration') {
        const importStatement: ImportStatement = {
          source: node.source?.value || '',
          specifiers: node.specifiers?.map(spec => ({
            type: spec.type,
            local: spec.local?.name || '',
            imported: spec.imported?.name || spec.local?.name || ''
          })) || [],
          isTypeOnly: node.importKind === 'type',
          location: {
            line: node.loc?.start?.line || 0,
            column: node.loc?.start?.column || 0
          }
        };
        imports.push(importStatement);
      }
    });

    // Resolve import paths and check if they exist
    for (const importStmt of imports) {
      importStmt.resolvedPath = await this.resolveImportPath(importStmt.source, filePath);
      importStmt.exists = await this.fileSystemReader.exists(importStmt.resolvedPath);
    }

    return imports;
  }

  private extractFunctions(ast: ASTNode, failureLine?: number): FunctionContext[] {
    const functions: FunctionContext[] = [];
    
    this.traverseAST(ast, (node) => {
      if (node.type === 'FunctionDeclaration' || 
          node.type === 'FunctionExpression' || 
          node.type === 'ArrowFunctionExpression') {
        
        const func: FunctionContext = {
          name: node.id?.name || 'anonymous',
          type: node.type,
          parameters: node.params?.map(param => ({
            name: param.name || param.pattern?.name || 'unknown',
            type: this.extractParameterType(param),
            defaultValue: param.defaultValue?.raw
          })) || [],
          returnType: this.extractReturnType(node),
          location: {
            startLine: node.loc?.start?.line || 0,
            endLine: node.loc?.end?.line || 0,
            column: node.loc?.start?.column || 0
          },
          isAsync: node.async || false,
          isGenerator: node.generator || false,
          scope: this.determineFunctionScope(node, failureLine)
        };
        
        functions.push(func);
      }
    });

    return functions.sort((a, b) => a.location.startLine - b.location.startLine);
  }

  private extractVariables(ast: ASTNode, failureLine?: number): VariableContext[] {
    const variables: VariableContext[] = [];
    
    this.traverseAST(ast, (node) => {
      if (node.type === 'VariableDeclaration') {
        node.declarations?.forEach(declaration => {
          const variable: VariableContext = {
            name: declaration.id?.name || 'unknown',
            type: this.inferVariableType(declaration),
            kind: node.kind || 'var', // const, let, var
            value: declaration.init?.raw || declaration.init?.value,
            location: {
              line: declaration.loc?.start?.line || 0,
              column: declaration.loc?.start?.column || 0
            },
            scope: this.determineVariableScope(node, failureLine),
            isInitialized: !!declaration.init
          };
          
          variables.push(variable);
        });
      }
    });

    return variables.sort((a, b) => a.location.line - b.location.line);
  }

  private async analyzeFileStructure(filePath: string): Promise<FileStructureInfo> {
    const directory = path.dirname(filePath);
    const files = await this.fileSystemReader.readDirectory(directory);
    
    return {
      directory,
      fileName: path.basename(filePath),
      fileExtension: path.extname(filePath),
      relatedFiles: files.filter(file => 
        file !== path.basename(filePath) && 
        this.isRelatedFile(file, filePath)
      ),
      packageInfo: await this.getPackageInfo(directory),
      gitInfo: await this.getGitInfo(directory)
    };
  }

  private async findRelatedSourceFiles(testFilePath: string): Promise<RelatedFile[]> {
    const relatedFiles: RelatedFile[] = [];
    
    // Common patterns for test file naming
    const patterns = [
      testFilePath.replace(/\.test\.(ts|js|tsx|jsx)$/, '.$1'),
      testFilePath.replace(/\.spec\.(ts|js|tsx|jsx)$/, '.$1'),
      testFilePath.replace(/test[s]?\//, 'src/').replace(/\.test\./, '.'),
      testFilePath.replace(/__tests__\//, 'src/').replace(/\.test\./, '.')
    ];

    for (const pattern of patterns) {
      if (await this.fileSystemReader.exists(pattern)) {
        const content = await this.fileSystemReader.readFile(pattern);
        relatedFiles.push({
          path: pattern,
          type: 'source',
          relationship: 'test-target',
          content: content.substring(0, 2000), // First 2KB for context
          exports: await this.extractExports(pattern)
        });
      }
    }

    return relatedFiles;
  }

  private traverseAST(node: ASTNode, visitor: (node: ASTNode) => void): void {
    visitor(node);
    
    if (node.body) {
      if (Array.isArray(node.body)) {
        node.body.forEach(child => this.traverseAST(child, visitor));
      } else {
        this.traverseAST(node.body, visitor);
      }
    }

    // Traverse other common AST properties
    const traversableProps = ['declarations', 'specifiers', 'params', 'arguments', 'elements'];
    
    for (const prop of traversableProps) {
      if (node[prop] && Array.isArray(node[prop])) {
        node[prop].forEach(child => {
          if (child && typeof child === 'object') {
            this.traverseAST(child, visitor);
          }
        });
      }
    }
  }
}

interface ImportStatement {
  source: string;
  specifiers: ImportSpecifier[];
  isTypeOnly: boolean;
  location: CodeLocation;
  resolvedPath?: string;
  exists?: boolean;
}

interface ImportSpecifier {
  type: string;
  local: string;
  imported: string;
}

interface FunctionContext {
  name: string;
  type: string;
  parameters: FunctionParameter[];
  returnType: string;
  location: FunctionLocation;
  isAsync: boolean;
  isGenerator: boolean;
  scope: 'global' | 'local' | 'closure';
}

interface VariableContext {
  name: string;
  type: string;
  kind: 'const' | 'let' | 'var';
  value: any;
  location: CodeLocation;
  scope: 'global' | 'function' | 'block';
  isInitialized: boolean;
}
```

#### 4.2 Puppeteer Visual Analysis Enhancement

**Advanced Puppeteer Analysis:**
```typescript
// src/components/analyzer/VisualAnalyzer.ts
export class VisualAnalyzer {
  private browser: Browser;
  private config: VisualAnalysisConfig;

  constructor(config: VisualAnalysisConfig) {
    this.config = config;
  }

  async initialize(): Promise<void> {
    this.browser = await puppeteer.launch({
      headless: this.config.headless,
      viewport: this.config.viewport,
      timeout: this.config.timeout
    });
  }

  async analyzeVisualFailure(
    failure: TestFailure, 
    classification: ErrorClassification
  ): Promise<VisualAnalysisReport | null> {
    
    // Only perform visual analysis for UI-related errors
    if (!this.shouldPerformVisualAnalysis(classification)) {
      return null;
    }

    const page = await this.browser.newPage();
    
    try {
      // Setup monitoring
      await this.setupPageMonitoring(page);
      
      // Navigate to the application
      const targetUrl = await this.determineTargetUrl(failure);
      if (!targetUrl) {
        return null;
      }

      await page.goto(targetUrl, { 
        waitUntil: 'networkidle2',
        timeout: this.config.navigationTimeout 
      });

      // Perform comprehensive analysis
      const [
        screenshot,
        domAnalysis,
        consoleErrors,
        networkIssues,
        performanceMetrics,
        accessibilityIssues,
        visualRegression
      ] = await Promise.all([
        this.captureScreenshot(page),
        this.analyzeDOMState(page, failure),
        this.getConsoleErrors(page),
        this.getNetworkIssues(page),
        this.capturePerformanceMetrics(page),
        this.analyzeAccessibility(page),
        this.detectVisualRegression(page, failure)
      ]);

      return {
        targetUrl,
        screenshot,
        domAnalysis,
        consoleErrors,
        networkIssues,
        performanceMetrics,
        accessibilityIssues,
        visualRegression,
        timestamp: new Date().toISOString(),
        analysisMetadata: {
          userAgent: await page.evaluate(() => navigator.userAgent),
          viewport: page.viewport(),
          deviceType: this.config.deviceType || 'desktop'
        }
      };

    } catch (error) {
      throw new VisualAnalysisError(
        `Visual analysis failed: ${error.message}`,
        error,
        { failure, targetUrl: await this.determineTargetUrl(failure) }
      );
    } finally {
      await page.close();
    }
  }

  private async setupPageMonitoring(page: Page): Promise<void> {
    // Monitor console messages
    page.on('console', msg => {
      this.consoleMessages.push({
        type: msg.type(),
        text: msg.text(),
        timestamp: new Date().toISOString()
      });
    });

    // Monitor network requests
    page.on('response', response => {
      if (!response.ok()) {
        this.networkIssues.push({
          url: response.url(),
          status: response.status(),
          statusText: response.statusText(),
          timestamp: new Date().toISOString()
        });
      }
    });

    // Monitor page errors
    page.on('pageerror', error => {
      this.pageErrors.push({
        message: error.message,
        stack: error.stack,
        timestamp: new Date().toISOString()
      });
    });
  }

  private async analyzeDOMState(page: Page, failure: TestFailure): Promise<DOMAnalysis> {
    return await page.evaluate((failureContext) => {
      const targetElement = failureContext.selector ? 
        document.querySelector(failureContext.selector) : null;
      
      // Get element information
      const elementInfo = targetElement ? {
        exists: true,
        visible: window.getComputedStyle(targetElement).display !== 'none',
        bounds: targetElement.getBoundingClientRect(),
        attributes: Object.fromEntries(
          Array.from(targetElement.attributes).map(attr => [attr.name, attr.value])
        ),
        computedStyles: {
          display: window.getComputedStyle(targetElement).display,
          visibility: window.getComputedStyle(targetElement).visibility,
          opacity: window.getComputedStyle(targetElement).opacity,
          position: window.getComputedStyle(targetElement).position,
          zIndex: window.getComputedStyle(targetElement).zIndex
        },
        textContent: targetElement.textContent || '',
        innerHTML: targetElement.innerHTML?.substring(0, 500) || '' // Limit for safety
      } : {
        exists: false,
        visible: false,
        bounds: null,
        attributes: {},
        computedStyles: {},
        textContent: '',
        innerHTML: ''
      };

      // Analyze page structure
      const pageStructure = {
        title: document.title,
        url: window.location.href,
        viewport: {
          width: window.innerWidth,
          height: window.innerHeight
        },
        documentReady: document.readyState,
        bodyClasses: Array.from(document.body.classList),
        metaTags: Array.from(document.querySelectorAll('meta')).map(meta => ({
          name: meta.getAttribute('name') || meta.getAttribute('property') || '',
          content: meta.getAttribute('content') || ''
        })),
        scripts: Array.from(document.querySelectorAll('script')).length,
        stylesheets: Array.from(document.querySelectorAll('link[rel="stylesheet"]')).length
      };

      // Check for common UI framework indicators
      const frameworkIndicators = {
        react: !!(window as any).React || document.querySelector('[data-reactroot]'),
        angular: !!(window as any).angular || !!(window as any).ng,
        vue: !!(window as any).Vue,
        jquery: !!(window as any).jQuery || !!(window as any).$
      };

      return {
        element: elementInfo,
        pageStructure,
        frameworkIndicators,
        timestamp: new Date().toISOString()
      };
    }, failure.context);
  }

  private async captureScreenshot(page: Page): Promise<string> {
    const screenshot = await page.screenshot({
      fullPage: true,
      type: 'png',
      quality: 90
    });
    return screenshot.toString('base64');
  }

  private async capturePerformanceMetrics(page: Page): Promise<PerformanceMetrics> {
    const metrics = await page.evaluate(() => {
      const perfData = performance.getEntriesByType('navigation')[0] as PerformanceNavigationTiming;
      const paintEntries = performance.getEntriesByType('paint');
      
      return {
        loadTime: perfData ? perfData.loadEventEnd - perfData.fetchStart : 0,
        domContentLoaded: perfData ? perfData.domContentLoadedEventEnd - perfData.fetchStart : 0,
        firstPaint: paintEntries.find(entry => entry.name === 'first-paint')?.startTime || 0,
        firstContentfulPaint: paintEntries.find(entry => entry.name === 'first-contentful-paint')?.startTime || 0,
        memoryUsage: (performance as any).memory ? {
          used: (performance as any).memory.usedJSHeapSize,
          total: (performance as any).memory.totalJSHeapSize,
          limit: (performance as any).memory.jsHeapSizeLimit
        } : null
      };
    });

    return metrics;
  }

  private shouldPerformVisualAnalysis(classification: ErrorClassification): boolean {
    const uiRelatedCategories = ['ui', 'network'];
    const uiRelatedSubCategories = [
      'element-not-found', 'event-handling', 'rendering-issue', 
      'state-management', 'http-request', 'connectivity'
    ];

    return uiRelatedCategories.includes(classification.category) ||
           uiRelatedSubCategories.includes(classification.subCategory);
  }

  private async determineTargetUrl(failure: TestFailure): Promise<string | null> {
    // Try to extract URL from test context
    if (failure.context.url) {
      return failure.context.url;
    }

    // Try to find development server URL
    const commonDevUrls = [
      'http://localhost:3000',
      'http://localhost:8080',
      'http://localhost:4200',
      'http://localhost:5173',
      'http://127.0.0.1:3000'
    ];

    for (const url of commonDevUrls) {
      try {
        const response = await fetch(url, { method: 'HEAD' });
        if (response.ok) {
          return url;
        }
      } catch {
        // Continue to next URL
      }
    }

    return null;
  }
}

interface VisualAnalysisReport {
  targetUrl: string;
  screenshot: string;
  domAnalysis: DOMAnalysis;
  consoleErrors: ConsoleError[];
  networkIssues: NetworkIssue[];
  performanceMetrics: PerformanceMetrics;
  accessibilityIssues: AccessibilityIssue[];
  visualRegression?: VisualRegressionData;
  timestamp: string;
  analysisMetadata: AnalysisMetadata;
}

interface DOMAnalysis {
  element: ElementInfo;
  pageStructure: PageStructure;
  frameworkIndicators: FrameworkIndicators;
  timestamp: string;
}

interface PerformanceMetrics {
  loadTime: number;
  domContentLoaded: number;
  firstPaint: number;
  firstContentfulPaint: number;
  memoryUsage: MemoryUsage | null;
}
```

#### 4.3 Testing Strategy for Step 4

**Unit Tests for Code Context Analysis:**
```typescript
// tests/unit/components/analyzer/CodeContextAnalyzer.test.ts
describe('CodeContextAnalyzer', () => {
  let analyzer: CodeContextAnalyzer;
  let mockASTParser: jest.Mocked<ASTParser>;
  let mockFileReader: jest.Mocked<FileSystemReader>;

  beforeEach(() => {
    mockASTParser = {
      parse: jest.fn()
    } as any;

    mockFileReader = {
      readFile: jest.fn(),
      exists: jest.fn(),
      readDirectory: jest.fn()
    } as any;

    analyzer = new CodeContextAnalyzer(
      mockASTParser,
      mockFileReader,
      {} as any
    );
  });

  describe('analyzeCodeContext', () => {
    it('should extract code context around failure point', async () => {
      const testFailure: TestFailure = {
        id: 'test-context-001',
        type: 'runtime',
        message: 'ReferenceError: userName is not defined',
        stackTrace: 'ReferenceError: userName is not defined\n    at UserProfile.test.js:15:23',
        testFile: './tests/UserProfile.test.js',
        lineNumber: 15,
        columnNumber: 23,
        context: {
          testName: 'should display user name',
          testSuite: 'UserProfile Tests',
          framework: 'jest',
          environment: 'development',
          dependencies: ['react', 'enzyme'],
          configuration: {}
        },
        timestamp: '2025-08-22T06:00:00.000Z',
        severity: 'high',
        metadata: {
          testRunner: 'jest',
          testFramework: 'jest',
          operatingSystem: 'darwin'
        }
      };

      const mockFileContent = `
import React from 'react';
import { shallow } from 'enzyme';
import UserProfile from '../UserProfile';

describe('UserProfile', () => {
  it('should display user name', () => {
    const wrapper = shallow(<UserProfile />);
    expect(wrapper.find('.username').text()).toBe(userName);
  });
});`.trim();

      const mockAST = {
        type: 'Program',
        body: [
          {
            type: 'ImportDeclaration',
            source: { value: 'react' },
            specifiers: [{ type: 'ImportDefaultSpecifier', local: { name: 'React' } }]
          }
        ]
      };

      mockFileReader.readFile.mockResolvedValue(mockFileContent);
      mockASTParser.parse.mockResolvedValue(mockAST);
      mockFileReader.exists.mockResolvedValue(true);
      mockFileReader.readDirectory.mockResolvedValue(['UserProfile.test.js', 'UserProfile.js']);

      const result = await analyzer.analyzeCodeContext(testFailure);

      expect(result.relevantCode).toContain('userName');
      expect(result.surroundingLines).toHaveLength(greaterThan(0));
      expect(result.surroundingLines.some(line => line.isHighlighted)).toBe(true);
      expect(result.imports).toHaveLength(1);
      expect(result.imports[0].source).toBe('react');
    });

    it('should identify missing imports causing reference errors', async () => {
      const testFailure: TestFailure = {
        id: 'test-context-002',
        type: 'runtime',
        message: 'ReferenceError: TestRenderer is not defined',
        stackTrace: 'ReferenceError: TestRenderer is not defined\n    at Component.test.js:5:12',
        testFile: './tests/Component.test.js',
        lineNumber: 5,
        context: {
          testName: 'should render component',
          testSuite: 'Component Tests',
          framework: 'jest',
          environment: 'development',
          dependencies: ['react'],
          configuration: {}
        },
        timestamp: '2025-08-22T06:00:00.000Z',
        severity: 'high',
        metadata: {
          testRunner: 'jest',
          testFramework: 'jest',
          operatingSystem: 'darwin'
        }
      };

      const mockFileContent = `
import React from 'react';
import Component from '../Component';

describe('Component', () => {
  it('should render component', () => {
    const renderer = TestRenderer.create(<Component />);
    expect(renderer.toJSON()).toMatchSnapshot();
  });
});`.trim();

      mockFileReader.readFile.mockResolvedValue(mockFileContent);
      mockASTParser.parse.mockResolvedValue({
        type: 'Program',
        body: []
      });

      const result = await analyzer.analyzeCodeContext(testFailure);

      expect(result.relevantCode).toContain('TestRenderer');
      expect(result.imports.some(imp => imp.source.includes('react-test-renderer'))).toBe(false);
    });
  });

  describe('extractSurroundingCode', () => {
    it('should extract correct number of context lines', () => {
      const content = Array.from({ length: 50 }, (_, i) => `Line ${i + 1}`).join('\n');
      const failureLine = 25;
      const contextLines = 5;

      const result = (analyzer as any).extractSurroundingCode(content, failureLine, contextLines);

      expect(result.lines).toHaveLength(11); // 5 before + failure line + 5 after
      expect(result.lines.find(line => line.isHighlighted)?.lineNumber).toBe(25);
      expect(result.lines[0].lineNumber).toBe(20);
      expect(result.lines[10].lineNumber).toBe(30);
    });
  });
});
```

**Integration Tests for Visual Analysis:**
```typescript
// tests/integration/visual-analysis.test.ts
describe('Visual Analysis Integration', () => {
  let visualAnalyzer: VisualAnalyzer;

  beforeAll(async () => {
    visualAnalyzer = new VisualAnalyzer({
      headless: true,
      viewport: { width: 1200, height: 800 },
      timeout: 30000,
      navigationTimeout: 15000
    });
    
    await visualAnalyzer.initialize();
  });

  afterAll(async () => {
    await visualAnalyzer.close();
  });

  it('should analyze UI-related test failure', async () => {
    const uiFailure: TestFailure = {
      id: 'ui-test-001',
      type: 'assertion',
      message: 'Element .submit-button not found',
      stackTrace: 'Error: Element .submit-button not found\n    at page.test.js:15',
      testFile: './tests/page.test.js',
      context: {
        testName: 'should have submit button',
        testSuite: 'Page Tests',
        framework: 'playwright',
        url: 'http://localhost:3000/test-page',
        selector: '.submit-button',
        environment: 'development',
        dependencies: ['playwright'],
        configuration: {}
      },
      timestamp: '2025-08-22T06:00:00.000Z',
      severity: 'medium',
      metadata: {
        testRunner: 'playwright',
        testFramework: 'playwright',
        operatingSystem: 'darwin'
      }
    };

    const classification: ErrorClassification = {
      category: 'ui',
      subCategory: 'element-not-found',
      severity: 'medium',
      confidence: 0.9,
      rootCause: 'DOM element with selector .submit-button does not exist',
      requiredExpertise: 'beginner',
      tags: ['dom', 'selector', 'element'],
      reasoning: 'Element selector could not locate the target element'
    };

    const result = await visualAnalyzer.analyzeVisualFailure(uiFailure, classification);

    if (result) {
      expect(result.screenshot).toBeDefined();
      expect(result.domAnalysis).toBeDefined();
      expect(result.domAnalysis.element.exists).toBe(false);
      expect(result.targetUrl).toContain('localhost:3000');
    }
  }, 45000);

  it('should skip visual analysis for non-UI errors', async () => {
    const logicFailure: TestFailure = {
      id: 'logic-test-001',
      type: 'runtime',
      message: 'TypeError: Cannot read property of undefined',
      stackTrace: 'TypeError: Cannot read property of undefined\n    at utils.test.js:10',
      testFile: './tests/utils.test.js',
      context: {
        testName: 'should process data',
        testSuite: 'Utils Tests',
        framework: 'jest',
        environment: 'development',
        dependencies: ['jest'],
        configuration: {}
      },
      timestamp: '2025-08-22T06:00:00.000Z',
      severity: 'high',
      metadata: {
        testRunner: 'jest',
        testFramework: 'jest',
        operatingSystem: 'darwin'
      }
    };

    const classification: ErrorClassification = {
      category: 'logic',
      subCategory: 'null-undefined-access',
      severity: 'high',
      confidence: 0.95,
      rootCause: 'Attempting to access property of undefined value',
      requiredExpertise: 'beginner',
      tags: ['logic', 'undefined', 'null-check'],
      reasoning: 'Classic undefined property access pattern'
    };

    const result = await visualAnalyzer.analyzeVisualFailure(logicFailure, classification);

    expect(result).toBeNull();
  });
});
```

**âœ… Step 4 Completion Criteria:**
- [ ] Code context analyzer extracting relevant code and imports
- [ ] AST parsing for function and variable analysis
- [ ] Visual analyzer with Puppeteer integration for UI failures
- [ ] DOM state analysis and screenshot capture
- [ ] Performance metrics collection during analysis
- [ ] Unit tests achieving 85% coverage for context analysis
- [ ] Integration tests validating visual analysis workflow
- [ ] Error handling for missing URLs and inaccessible applications

---

### Step 5: Web Research & Solution Mining Engine
**â±ï¸ Duration**: Day 3 (Morning - 4 hours)  
**Priority**: High - Community knowledge integration

#### ğŸ¯ Step 5 Goals
- **Primary Goal**: Build intelligent web research system for solution mining
- **Secondary Goal**: Implement AI-powered solution ranking and relevance analysis
- **Tertiary Goal**: Create efficient caching and rate limiting for API usage

#### ğŸ“‹ Success Criteria
- Multi-provider search capability operational
- AI-powered solution ranking with >90% relevance
- Caching mechanism reducing API calls by 70%
- Integration with Stack Overflow and GitHub APIs

#### 5.1 Comprehensive Web Research Implementation

**Advanced Web Research Service:**
```typescript
// src/components/research/WebResearchService.ts
export class WebResearchService {
  constructor(
    private neurolinkService: NeuroLinkService,
    private searchProviders: SearchProvider[],
    private cache: SearchCacheManager,
    private config: WebResearchConfig
  ) {}

  async searchSolutions(failure: TestFailure): Promise<WebSolutionResults> {
    try {
      const startTime = Date.now();

      // 1. Generate intelligent search queries
      const queries = await this.generateSearchQueries(failure);

      // 2. Check cache for existing results
      const cachedResults = await this.getCachedResults(queries);
      
      // 3. Perform searches across multiple providers
      const searchResults = await this.performMultiProviderSearch(
        queries.filter(q => !cachedResults.has(q))
      );

      // 4. Combine cached and fresh results
      const allResults = this.combineResults(cachedResults, searchResults);

      // 5. AI-powered relevance analysis and ranking
      const rankedSolutions = await this.rankAndAnalyzeSolutions(allResults, failure);

      // 6. Cache new results
      await this.cacheResults(searchResults);

      const researchTime = Date.now() - startTime;

      return {
        originalQueries: queries,
        totalResults: allResults.length,
        relevantSolutions: rankedSolutions,
        searchSources: this.searchProviders.map(p => p.name),
        confidenceScores: rankedSolutions.map(s => s.confidence),
        researchTime,
        cacheHitRate: cachedResults.size / queries.length,
        metadata: {
          providersUsed: this.searchProviders.filter(p => p.enabled).length,
          queriesGenerated: queries.length,
          resultsFiltered: allResults.length - rankedSolutions.length
        }
      };

    } catch (error) {
      throw new WebResearchError(
        `Web research failed: ${error.message}`,
        error,
        { failure }
      );
    }
  }

  private async generateSearchQueries(failure: TestFailure): Promise<string[]> {
    // Base queries using error details
    const baseQueries = this.generateBaseQueries(failure);
    
    // AI-enhanced query generation
    const aiQueries = await this.generateAIQueries(failure);
    
    // Framework-specific queries
    const frameworkQueries = this.generateFrameworkSpecificQueries(failure);
    
    // Combine and deduplicate
    const allQueries = [...baseQueries, ...aiQueries, ...frameworkQueries];
    return this.deduplicateQueries(allQueries);
  }

  private generateBaseQueries(failure: TestFailure): string[] {
    const errorMessage = this.sanitizeErrorMessage(failure.message);
    const framework = failure.context.framework;
    const testFramework = failure.metadata.testFramework;

    return [
      // Exact error message searches
      `"${errorMessage}" ${framework} ${testFramework}`,
      `"${errorMessage}" ${framework} solution`,
      `"${errorMessage}" fix resolved`,
      
      // Error type + framework searches
      `${failure.type} error ${framework} ${testFramework}`,
      `${framework} ${failure.type} troubleshooting`,
      `how to fix ${failure.type} in ${framework}`,
      
      // Stack Overflow specific
      `site:stackoverflow.com "${errorMessage}" ${framework}`,
      `site:stackoverflow.com ${failure.type} ${framework} solved`,
      
      // GitHub specific
      `site:github.com "${errorMessage}" ${framework} issue`,
      `site:github.com ${framework} ${failure.type} bug fix`,
      
      // Documentation searches
      `${framework} documentation ${failure.type}`,
      `${testFramework} documentation error handling`
    ];
  }

  private async generateAIQueries(failure: TestFailure): Promise<string[]> {
    const prompt = `Generate search queries to find solutions for this test error:

Error: ${failure.message}
Type: ${failure.type}
Framework: ${failure.context.framework}
Test Framework: ${failure.metadata.testFramework}

Generate 5-7 diverse search queries that would help find:
1. Exact solutions for this specific error
2. Related issues and workarounds
3. Documentation and best practices
4. Community discussions and forum posts

Focus on queries that would return high-quality, actionable results.
Return only the search queries, one per line.`;

    const response = await this.neurolinkService.analyze({
      prompt,
      context: {
        taskType: 'query-generation',
        errorType: failure.type,
        framework: failure.context.framework
      },
      temperature: 0.7, // Higher creativity for diverse queries
      maxTokens: 300
    });

    return response.content
      .split('\n')
      .map(query => query.trim())
      .filter(query => query.length > 0)
      .slice(0, 7); // Limit to 7 queries
  }

  private async performMultiProviderSearch(queries: string[]): Promise<SearchResult[]> {
    const searchPromises = this.searchProviders
      .filter(provider => provider.enabled)
      .flatMap(provider => 
        queries.map(query => 
          this.searchWithProvider(provider, query)
            .catch(error => ({
              provider: provider.name,
              query,
              error: error.message,
              results: []
            }))
        )
      );

    const searchResponses = await Promise.allSettled(searchPromises);
    
    return searchResponses
      .filter(response => response.status === 'fulfilled')
      .flatMap(response => response.value.results || []);
  }

  private async searchWithProvider(provider: SearchProvider, query: string): Promise<ProviderSearchResult> {
    switch (provider.name) {
      case 'stackoverflow':
        return await this.searchStackOverflow(query);
      case 'github':
        return await this.searchGitHub(query);
      case 'google':
        return await this.searchGoogle(query);
      case 'bing':
        return await this.searchBing(query);
      default:
        throw new Error(`Unknown search provider: ${provider.name}`);
    }
  }

  private async searchStackOverflow(query: string): Promise<ProviderSearchResult> {
    const apiUrl = `https://api.stackexchange.com/2.3/search/advanced`;
    const params = new URLSearchParams({
      order: 'desc',
      sort: 'relevance',
      q: query,
      site: 'stackoverflow',
      filter: 'withbody',
      pagesize: '10'
    });

    const response = await fetch(`${apiUrl}?${params}`);
    const data = await response.json();

    const results = data.items?.map(item => ({
      id: `so_${item.question_id}`,
      title: item.title,
      url: item.link,
      snippet: this.extractSnippet(item.body, 300),
      source: 'stackoverflow',
      score: item.score,
      metadata: {
        answers: item.answer_count,
        accepted: item.is_answered,
        upvotes: item.up_vote_count,
        tags: item.tags,
        created: item.creation_date
      }
    })) || [];

    return {
      provider: 'stackoverflow',
      query,
      results,
      totalResults: data.total || 0,
      searchTime: Date.now()
    };
  }

  private async searchGitHub(query: string): Promise<ProviderSearchResult> {
    const apiUrl = 'https://api.github.com/search/issues';
    const params = new URLSearchParams({
      q: `${query} type:issue state:closed`,
      sort: 'relevance',
      order: 'desc',
      per_page: '10'
    });

    const response = await fetch(`${apiUrl}?${params}`, {
      headers: {
        'Accept': 'application/vnd.github.v3+json',
        'User-Agent': 'Neurolink-Testing-Agent/1.0'
      }
    });
    const data = await response.json();

    const results = data.items?.map(item => ({
      id: `gh_${item.id}`,
      title: item.title,
      url: item.html_url,
      snippet: this.extractSnippet(item.body, 300),
      source: 'github',
      score: this.calculateGitHubScore(item),
      metadata: {
        state: item.state,
        comments: item.comments,
        labels: item.labels?.map(label => label.name),
        repository: item.repository_url,
        created: item.created_at,
        updated: item.updated_at
      }
    })) || [];

    return {
      provider: 'github',
      query,
      results,
      totalResults: data.total_count || 0,
      searchTime: Date.now()
    };
  }

  private async rankAndAnalyzeSolutions(
    results: SearchResult[],
    failure: TestFailure
  ): Promise<RankedSolution[]> {
    if (results.length === 0) {
      return [];
    }

    const analysisPrompt = `Analyze these search results for solutions to the test error and rank them by relevance and quality:

ERROR DETAILS:
- Message: ${failure.message}
- Type: ${failure.type}
- Framework: ${failure.context.framework}
- Test Framework: ${failure.metadata.testFramework}

SEARCH RESULTS:
${results.map((result, index) => `
${index + 1}. ${result.title}
   Source: ${result.source}
   URL: ${result.url}
   Score: ${result.score}
   Snippet: ${result.snippet}
   Metadata: ${JSON.stringify(result.metadata)}
`).join('\n')}

For each relevant result (relevance score >= 6), provide analysis in this JSON format:
{
  "relevantResults": [
    {
      "index": number, // 1-based index from above list
      "relevanceScore": number, // 1-10
      "solutionType": "fix|workaround|explanation|documentation",
      "confidence": "high|medium|low",
      "insights": "key insights or solution summary",
      "difficulty": "easy|medium|hard",
      "risks": ["potential risk 1", "potential risk 2"],
      "reasoning": "why this solution is relevant and trustworthy"
    }
  ]
}

Focus on:
1. Direct solutions that fix the exact error
2. Workarounds that avoid the problem
3. Explanations that help understand the root cause
4. High-quality sources (accepted answers, recent updates, good scores)

Return only the JSON response.`;

    const analysis = await this.neurolinkService.analyze({
      prompt: analysisPrompt,
      context: {
        taskType: 'solution-ranking',
        errorType: failure.type,
        framework: failure.context.framework
      },
      temperature: 0.1, // Low temperature for consistent analysis
      maxTokens: 2000
    });

    return this.parseSolutionAnalysis(analysis, results);
  }

  private parseSolutionAnalysis(
    analysis: AIAnalysisResponse,
    originalResults: SearchResult[]
  ): RankedSolution[] {
    try {
      const parsed = JSON.parse(analysis.content);
      
      return parsed.relevantResults
        .map(item => {
          const originalResult = originalResults[item.index - 1];
          if (!originalResult) return null;

          return {
            id: originalResult.id,
            title: originalResult.title,
            url: originalResult.url,
            source: originalResult.source,
            relevanceScore: item.relevanceScore,
            solutionType: item.solutionType,
            confidence: item.confidence,
            insights: item.insights,
            implementation: {
              difficulty: item.difficulty,
              estimatedTime: this.estimateImplementationTime(item.difficulty),
              steps: [],
              prerequisites: []
            },
            difficulty: item.difficulty,
            risks: item.risks || [],
            upvotes: originalResult.metadata?.upvotes || originalResult.score,
            acceptedAnswer: originalResult.metadata?.accepted || false,
            lastUpdated: originalResult.metadata?.updated || originalResult.metadata?.created || '',
            reasoning: item.reasoning
          };
        })
        .filter(item => item !== null)
        .sort((a, b) => b.relevanceScore - a.relevanceScore);

    } catch (error) {
      throw new SolutionAnalysisError(
        `Failed to parse solution analysis: ${error.message}`,
        error,
        { analysis: analysis.content }
      );
    }
  }

  private estimateImplementationTime(difficulty: string): number {
    switch (difficulty) {
      case 'easy': return 5; // 5 minutes
      case 'medium': return 15; // 15 minutes
      case 'hard': return 45; // 45 minutes
      default: return 10;
    }
  }

  private calculateGitHubScore(item: any): number {
    // Score based on comments, state, and age
    let score = 0;
    
    if (item.state === 'closed') score += 5;
    score += Math.min(item.comments * 0.5, 10);
    
    // Boost recent issues
    const ageInDays = (Date.now() - new Date(item.created_at).getTime()) / (1000 * 60 * 60 * 24);
    if (ageInDays < 365) score += 3;
    
    return Math.round(score);
  }

  private sanitizeErrorMessage(message: string): string {
    return message
      .replace(/['"]/g, '') // Remove quotes
      .replace(/\s+/g, ' ') // Normalize whitespace
      .trim()
      .substring(0, 100); // Limit length
  }

  private extractSnippet(content: string, maxLength: number): string {
    if (!content) return '';
    
    // Remove HTML tags and clean up content
    const cleaned = content
      .replace(/<[^>]*>/g, '') // Remove HTML tags
      .replace(/\s+/g, ' ') // Normalize whitespace
      .trim();
    
    if (cleaned.length <= maxLength) {
      return cleaned;
    }
    
    // Truncate and add ellipsis
    return cleaned.substring(0, maxLength - 3) + '...';
  }

  private deduplicateQueries(queries: string[]): string[] {
    const seen = new Set<string>();
    return queries.filter(query => {
      const normalized = query.toLowerCase().trim();
      if (seen.has(normalized)) {
        return false;
      }
      seen.add(normalized);
      return true;
    });
  }

  private generateFrameworkSpecificQueries(failure: TestFailure): string[] {
    const framework = failure.context.framework;
    const testFramework = failure.metadata.testFramework;
    
    const frameworkSpecificQueries = [];
    
    // Framework-specific error patterns
    if (framework === 'react') {
      frameworkSpecificQueries.push(
        `react ${failure.type} error testing`,
        `react testing library ${failure.message}`,
        `react component test error`,
        `enzyme react testing error`
      );
    } else if (framework === 'angular') {
      frameworkSpecificQueries.push(
        `angular ${failure.type} testing error`,
        `angular jasmine karma ${failure.message}`,
        `angular component testing error`
      );
    } else if (framework === 'vue') {
      frameworkSpecificQueries.push(
        `vue ${failure.type} testing error`,
        `vue test utils ${failure.message}`,
        `vue component testing error`
      );
    }
    
    // Test framework specific
    if (testFramework === 'jest') {
      frameworkSpecificQueries.push(
        `jest ${failure.type} error solution`,
        `jest testing ${failure.message}`,
        `jest configuration ${failure.type}`
      );
    } else if (testFramework === 'cypress') {
      frameworkSpecificQueries.push(
        `cypress ${failure.type} error fix`,
        `cypress e2e testing ${failure.message}`,
        `cypress test error solution`
      );
    }
    
    return frameworkSpecificQueries;
  }
}

interface SearchProvider {
  name: string;
  enabled: boolean;
  endpoint?: string;
  apiKey?: string;
  rateLimits: {
    requestsPerMinute: number;
    requestsPerHour: number;
  };
}

interface ProviderSearchResult {
  provider: string;
  query: string;
  results: SearchResult[];
  totalResults: number;
  searchTime: number;
}

interface SearchResult {
  id: string;
  title: string;
  url: string;
  snippet: string;
  source: string;
  score: number;
  metadata: any;
}

interface WebResearchConfig {
  maxResultsPerProvider: number;
  timeoutMs: number;
  enableCaching: boolean;
  cacheExpiryMs: number;
  enableAIRanking: boolean;
  minRelevanceScore: number;
}
```

#### 5.2 Testing Strategy for Step 5

**Unit Tests for Web Research:**
```typescript
// tests/unit/components/research/WebResearchService.test.ts
describe('WebResearchService', () => {
  let service: WebResearchService;
  let mockNeuroLink: jest.Mocked<NeuroLinkService>;
  let mockCache: jest.Mocked<SearchCacheManager>;

  beforeEach(() => {
    mockNeuroLink = {
      analyze: jest.fn()
    } as any;

    mockCache = {
      getCachedResults: jest.fn(),
      cacheResults: jest.fn()
    } as any;

    const config: WebResearchConfig = {
      maxResultsPerProvider: 10,
      timeoutMs: 30000,
      enableCaching: true,
      cacheExpiryMs: 3600000,
      enableAIRanking: true,
      minRelevanceScore: 6
    };

    service = new WebResearchService(
      mockNeuroLink,
      [
        { name: 'stackoverflow', enabled: true, rateLimits: { requestsPerMinute: 30, requestsPerHour: 300 } },
        { name: 'github', enabled: true, rateLimits: { requestsPerMinute: 10, requestsPerHour: 100 } }
      ],
      mockCache,
      config
    );
  });

  describe('searchSolutions', () => {
    it('should generate and execute search queries', async () => {
      const testFailure: TestFailure = {
        id: 'research-test-001',
        type: 'runtime',
        message: 'ReferenceError: React is not defined',
        stackTrace: 'ReferenceError: React is not defined\n    at Component.test.js:5',
        testFile: './tests/Component.test.js',
        context: {
          testName: 'should render component',
          testSuite: 'Component Tests',
          framework: 'react',
          environment: 'development',
          dependencies: ['react', 'jest'],
          configuration: {}
        },
        timestamp: '2025-08-22T06:00:00.000Z',
        severity: 'high',
        metadata: {
          testRunner: 'jest',
          testFramework: 'jest',
          operatingSystem: 'darwin'
        }
      };

      // Mock cache miss
      mockCache.getCachedResults.mockResolvedValue(new Map());

      // Mock AI query generation
      mockNeuroLink.analyze.mockResolvedValueOnce({
        content: `"React is not defined" react testing solution
react import error fix
react testing library import issue
jest react component test error
how to import React in jest tests`,
        provider: 'openai',
        confidence: 0.9,
        usage: { totalTokens: 100 },
        metadata: { responseTime: 1000, retryAttempts: 0, requestId: 'req-001', timestamp: '' },
        cached: false
      });

      // Mock search results ranking
      mockNeuroLink.analyze.mockResolvedValueOnce({
        content: JSON.stringify({
          relevantResults: [
            {
              index: 1,
              relevanceScore: 9,
              solutionType: 'fix',
              confidence: 'high',
              insights: 'Missing React import in test file',
              difficulty: 'easy',
              risks: [],
              reasoning: 'Direct solution for React import error'
            }
          ]
        }),
        provider: 'openai',
        confidence: 0.95,
        usage: { totalTokens: 200 },
        metadata: { responseTime: 1200, retryAttempts: 0, requestId: 'req-002', timestamp: '' },
        cached: false
      });

      // Mock search provider (we'll need to mock the actual HTTP calls)
      jest.spyOn(global, 'fetch').mockImplementation((url) => {
        if (url.includes('stackexchange.com')) {
          return Promise.resolve({
            json: () => Promise.resolve({
              items: [{
                question_id: 123,
                title: 'React is not defined in Jest tests',
                link: 'https://stackoverflow.com/questions/123',
                body: 'You need to import React in your test files...',
                score: 15,
                answer_count: 3,
                is_answered: true,
                up_vote_count: 15,
                tags: ['reactjs', 'jest', 'testing']
              }],
              total: 1
            })
          } as any);
        }
        return Promise.reject(new Error('Unknown URL'));
      });

      const result = await service.searchSolutions(testFailure);

      expect(result.originalQueries).toHaveLength(greaterThan(5));
      expect(result.originalQueries.some(q => q.includes('React is not defined'))).toBe(true);
      expect(result.relevantSolutions).toHaveLength(greaterThan(0));
      expect(result.relevantSolutions[0].relevanceScore).toBeGreaterThan(6);
      expect(result.researchTime).toBeGreaterThan(0);

      // Cleanup
      (global.fetch as jest.Mock).mockRestore();
    });

    it('should handle API rate limiting gracefully', async () => {
      const testFailure: TestFailure = {
        id: 'rate-limit-test',
        type: 'timeout',
        message: 'Test timeout exceeded',
        stackTrace: 'Error: Test timeout\n    at test.js:10',
        testFile: './tests/timeout.test.js',
        context: {
          testName: 'should handle async operations',
          testSuite: 'Async Tests',
          framework: 'jest',
          environment: 'development',
          dependencies: ['jest'],
          configuration: {}
        },
        timestamp: '2025-08-22T06:00:00.000Z',
        severity: 'medium',
        metadata: {
          testRunner: 'jest',
          testFramework: 'jest',
          operatingSystem: 'darwin'
        }
      };

      mockCache.getCachedResults.mockResolvedValue(new Map());
      mockNeuroLink.analyze.mockResolvedValue({
        content: 'jest timeout error solution',
        provider: 'openai',
        confidence: 0.8,
        usage: { totalTokens: 50 },
        metadata: { responseTime: 800, retryAttempts: 0, requestId: 'req-003', timestamp: '' },
        cached: false
      });

      // Mock rate limit error
      jest.spyOn(global, 'fetch').mockRejectedValue(new Error('Rate limit exceeded'));

      const result = await service.searchSolutions(testFailure);

      // Should handle gracefully and return empty results
      expect(result.totalResults).toBe(0);
      expect(result.relevantSolutions).toHaveLength(0);
      expect(result.originalQueries).toHaveLength(greaterThan(0));

      (global.fetch as jest.Mock).mockRestore();
    });
  });

  describe('generateSearchQueries', () => {
    it('should generate diverse search queries', async () => {
      const failure: TestFailure = {
        id: 'query-test',
        type: 'assertion',
        message: 'Expected 5 but received 3',
        stackTrace: 'AssertionError\n    at test.js:20',
        testFile: './tests/math.test.js',
        context: {
          testName: 'should calculate sum',
          testSuite: 'Math Tests',
          framework: 'jest',
          environment: 'development',
          dependencies: ['jest'],
          configuration: {}
        },
        timestamp: '2025-08-22T06:00:00.000Z',
        severity: 'medium',
        metadata: {
          testRunner: 'jest',
          testFramework: 'jest',
          operatingSystem: 'darwin'
        }
      };

      mockNeuroLink.analyze.mockResolvedValue({
        content: `assertion error expected 5 received 3 jest
jest assertion failure debugging
javascript test assertion error fix
unit test assertion mismatch solution`,
        provider: 'openai',
        confidence: 0.85,
        usage: { totalTokens: 80 },
        metadata: { responseTime: 900, retryAttempts: 0, requestId: 'req-004', timestamp: '' },
        cached: false
      });

      const queries = await (service as any).generateSearchQueries(failure);

      expect(queries).toHaveLength(greaterThan(10));
      expect(queries.some(q => q.includes('Expected 5 but received 3'))).toBe(true);
      expect(queries.some(q => q.includes('jest'))).toBe(true);
      expect(queries.some(q => q.includes('assertion'))).toBe(true);
      expect(queries.some(q => q.includes('site:stackoverflow.com'))).toBe(true);
    });
  });
});
```

**Integration Tests:**
```typescript
// tests/integration/web-research-integration.test.ts
describe('Web Research Integration', () => {
  let service: WebResearchService;

  beforeAll(() => {
    if (!process.env.GOOGLE_SEARCH_API_KEY) {
      pending('Google Search API key not configured');
    }

    service = new WebResearchService(
      new NeuroLinkService(/* config */),
      [
        { 
          name: 'google',
          enabled: true,
          apiKey: process.env.GOOGLE_SEARCH_API_KEY,
          rateLimits: { requestsPerMinute: 5, requestsPerHour: 50 }
        }
      ],
      new SearchCacheManager(),
      {
        maxResultsPerProvider: 5,
        timeoutMs: 15000,
        enableCaching: false,
        cacheExpiryMs: 0,
        enableAIRanking: true,
        minRelevanceScore: 6
      }
    );
  });

  it('should find real solutions for common JavaScript errors', async () => {
    const commonError: TestFailure = {
      id: 'integration-test-001',
      type: 'runtime',
      message: 'TypeError: Cannot read property of undefined',
      stackTrace: 'TypeError: Cannot read property of undefined\n    at utils.js:15',
      testFile: './tests/utils.test.js',
      context: {
        testName: 'should process user data',
        testSuite: 'Utils Tests',
        framework: 'jest',
        environment: 'development',
        dependencies: ['jest', 'lodash'],
        configuration: {}
      },
      timestamp: '2025-08-22T06:00:00.000Z',
      severity: 'high',
      metadata: {
        testRunner: 'jest',
        testFramework: 'jest',
        operatingSystem: 'darwin'
      }
    };

    const results = await service.searchSolutions(commonError);

    expect(results.totalResults).toBeGreaterThan(0);
    expect(results.relevantSolutions.length).toBeGreaterThan(0);
    expect(results.relevantSolutions[0].relevanceScore).toBeGreaterThanOrEqual(6);
    expect(results.researchTime).toBeLessThan(30000); // Should complete in 30 seconds
    
    // Check that we got meaningful solutions
    const topSolution = results.relevantSolutions[0];
    expect(topSolution.insights).toBeTruthy();
    expect(topSolution.url).toMatch(/^https?:\/\//);
    expect(['fix', 'workaround', 'explanation', 'documentation']).toContain(topSolution.solutionType);
  }, 45000);
});
```

**âœ… Step 5 Completion Criteria:**
- [ ] Web research service with multi-provider search capability
- [ ] AI-powered query generation for diverse search strategies
- [ ] Stack Overflow and GitHub API integration working
- [ ] Solution ranking and analysis using AI consensus
- [ ] Caching mechanism for search result optimization
- [ ] Unit tests achieving 85% coverage for search logic
- [ ] Integration tests validating real API communication
- [ ] Rate limiting and error handling for API failures

---

### Step 6: Fix Suggestion Engine & CLI Interface
**â±ï¸ Duration**: Day 3 (Afternoon - 4 hours)  
**Priority**: High - Final integration and user interface

#### ğŸ¯ Step 6 Goals
- **Primary Goal**: Generate comprehensive, actionable fix suggestions
- **Secondary Goal**: Create intuitive CLI interface for seamless developer experience
- **Tertiary Goal**: Implement rich reporting dashboard with visual evidence

#### ğŸ“‹ Success Criteria
- Fix suggestions with >80% implementation success rate
- CLI interface providing immediate developer value
- HTML reports with visual evidence and interactive elements
- Integration with existing development workflows

#### 6.1 Comprehensive Fix Suggestion Engine

**Advanced Fix Suggestion Implementation:**
```typescript
// src/components/suggester/FixSuggestionEngine.ts
export class FixSuggestionEngine {
  constructor(
    private neurolinkService: NeuroLinkService,
    private confidenceScorer: ConfidenceScorer,
    private solutionValidator: SolutionValidator,
    private config: SuggestionEngineConfig
  ) {}

  async generateFixSuggestions(
    error: TestFailure,
    classification: ErrorClassification,
    codeContext: CodeContext,
    visualAnalysis: VisualAnalysisReport | null,
    webSolutions: WebSolutionResults
  ): Promise<FixSuggestion[]> {
    try {
      // 1. Generate suggestions using multiple AI approaches
      const suggestionPrompts = this.buildSuggestionPrompts(
        error, classification, codeContext, visualAnalysis, webSolutions
      );

      const [primarySuggestions, alternativeSuggestions, preventiveSuggestions] = await Promise.all([
        this.generatePrimarySuggestions(suggestionPrompts.detailed),
        this.generateAlternativeSuggestions(suggestionPrompts.alternative),
        this.generatePreventiveSuggestions(suggestionPrompts.preventive)
      ]);

      // 2. Consolidate and validate suggestions
      const allSuggestions = [
        ...primarySuggestions,
        ...alternativeSuggestions,
        ...preventiveSuggestions
      ];

      // 3. Score confidence and validate feasibility
      const scoredSuggestions = await this.scoreAndValidateSuggestions(
        allSuggestions, error, classification, webSolutions
      );

      // 4. Generate implementation guides
      const enhancedSuggestions = await this.enhanceWithImplementationGuides(scoredSuggestions);

      // 5. Sort by confidence and practicality
      return enhancedSuggestions
        .filter(suggestion => suggestion.confidence > this.config.minConfidenceThreshold)
        .sort((a, b) => this.calculateOverallScore(b) - this.calculateOverallScore(a))
        .slice(0, this.config.maxSuggestions);

    } catch (error) {
      throw new FixSuggestionError(
        `Failed to generate fix suggestions: ${error.message}`,
        error,
        { error, classification }
      );
    }
  }

  private async generatePrimarySuggestions(prompt: string): Promise<RawFixSuggestion[]> {
    const response = await this.neurolinkService.analyze({
      prompt,
      context: {
        taskType: 'fix-generation',
        approach: 'primary-solution'
      },
      temperature: 0.2, // Low temperature for focused solutions
      maxTokens: 1500
    });

    return this.parseSuggestionResponse(response, 'primary');
  }

  private async generateAlternativeSuggestions(prompt: string): Promise<RawFixSuggestion[]> {
    const response = await this.neurolinkService.analyze({
      prompt,
      context: {
        taskType: 'fix-generation',
        approach: 'alternative-solutions'
      },
      temperature: 0.4, // Medium temperature for creative alternatives
      maxTokens: 1200
    });

    return this.parseSuggestionResponse(response, 'alternative');
  }

  private async generatePreventiveSuggestions(prompt: string): Promise<RawFixSuggestion[]> {
    const response = await this.neurolinkService.analyze({
      prompt,
      context: {
        taskType: 'fix-generation',
        approach: 'preventive-measures'
      },
      temperature: 0.3, // Balanced temperature for best practices
      maxTokens: 1000
    });

    return this.parseSuggestionResponse(response, 'preventive');
  }

  private buildSuggestionPrompts(
    error: TestFailure,
    classification: ErrorClassification,
    codeContext: CodeContext,
    visualAnalysis: VisualAnalysisReport | null,
    webSolutions: WebSolutionResults
  ) {
    const baseContext = this.buildBaseContext(error, classification, codeContext, visualAnalysis, webSolutions);

    return {
      detailed: `${baseContext}

TASK: Generate a comprehensive, step-by-step fix for this error.

REQUIRED OUTPUT FORMAT (JSON):
{
  "suggestions": [
    {
      "id": "unique-id",
      "title": "concise fix title",
      "description": "detailed description of the fix",
      "category": "immediate-fix|configuration|code-change|dependency",
      "priority": "high|medium|low",
      "implementation": {
        "steps": [
          {
            "step": 1,
            "action": "specific action to take",
            "code": "code changes if applicable",
            "file": "file to modify if applicable",
            "explanation": "why this step is necessary"
          }
        ],
        "estimatedTime": "time in minutes",
        "difficulty": "easy|medium|hard",
        "requiresRestart": boolean
      },
      "verification": [
        "step 1 to verify fix works",
        "step 2 to verify fix works"
      ],
      "risks": ["potential risk 1", "potential risk 2"],
      "rollbackSteps": ["how to undo if needed"]
    }
  ]
}

Focus on:
1. Root cause analysis and direct solution
2. Exact code changes with before/after examples
3. Specific file modifications needed
4. Clear verification steps
5. Risk assessment and rollback plan

Provide only the JSON response.`,

      alternative: `${baseContext}

TASK: Generate alternative approaches and workarounds for this error.

REQUIRED OUTPUT FORMAT (JSON):
{
  "alternatives": [
    {
      "id": "unique-id",
      "title": "alternative approach title",
      "description": "description of alternative solution",
      "type": "workaround|refactor|configuration|tooling",
      "tradeoffs": {
        "pros": ["advantage 1", "advantage 2"],
        "cons": ["disadvantage 1", "disadvantage 2"]
      },
      "implementation": {
        "steps": ["step 1", "step 2"],
        "difficulty": "easy|medium|hard",
        "timeInvestment": "time required"
      },
      "suitability": "when to use this approach",
      "migrationPath": "how to transition from workaround to permanent fix"
    }
  ]
}

Focus on:
1. Creative workarounds when direct fix is complex
2. Different architectural approaches
3. Tool or configuration changes
4. Trade-offs between approaches
5. Migration strategies

Provide only the JSON response.`,

      preventive: `${baseContext}

TASK: Generate preventive measures and best practices to avoid this error in the future.

REQUIRED OUTPUT FORMAT (JSON):
{
  "preventiveMeasures": [
    {
      "id": "unique-id",
      "title": "preventive measure title",
      "description": "description of preventive approach",
      "category": "code-pattern|testing-strategy|tooling|process",
      "implementation": {
        "setup": ["setup step 1", "setup step 2"],
        "ongoing": ["ongoing practice 1", "ongoing practice 2"]
      },
      "tooling": {
        "linters": ["linting rule suggestions"],
        "staticAnalysis": ["static analysis tool suggestions"],
        "testing": ["testing strategy improvements"]
      },
      "documentation": "team documentation suggestions",
      "training": "team knowledge sharing recommendations"
    }
  ]
}

Focus on:
1. Code patterns that prevent this error type
2. Testing strategies to catch issues earlier
3. Development workflow improvements
4. Tooling and automation suggestions
5. Team knowledge sharing approaches

Provide only the JSON response.`
    };
  }

  private buildBaseContext(
    error: TestFailure,
    classification: ErrorClassification,
    codeContext: CodeContext,
    visualAnalysis: VisualAnalysisReport | null,
    webSolutions: WebSolutionResults
  ): string {
    return `ERROR ANALYSIS CONTEXT:

Error Details:
- Type: ${error.type}
- Message: ${error.message}
- File: ${error.testFile}
- Line: ${error.lineNumber || 'unknown'}
- Severity: ${error.severity}

Classification:
- Category: ${classification.category}
- Subcategory: ${classification.subCategory}
- Root Cause: ${classification.rootCause}
- Required Expertise: ${classification.requiredExpertise}
- Confidence: ${classification.confidence}

Code Context:
${codeContext.relevantCode}

Imports:
${codeContext.imports.map(imp => `- ${imp.source} (${imp.exists ? 'exists' : 'missing'})`).join('\n')}

Framework Context:
- Framework: ${error.context.framework}
- Test Framework: ${error.metadata.testFramework}
- Environment: ${error.context.environment}
- Dependencies: ${error.context.dependencies.join(', ')}

${visualAnalysis ? `Visual Analysis:
- Target URL: ${visualAnalysis.targetUrl}
- Element Exists: ${visualAnalysis.domAnalysis.element.exists}
- Element Visible: ${visualAnalysis.domAnalysis.element.visible}
- Console Errors: ${visualAnalysis.consoleErrors.length} errors found
- Network Issues: ${visualAnalysis.networkIssues.length} issues found` : 'Visual Analysis: N/A (non-UI error)'}

Community Solutions Found:
${webSolutions.relevantSolutions.slice(0, 3).map(sol => 
  `- ${sol.title} (${sol.confidence} confidence, ${sol.solutionType})
    Insights: ${sol.insights}
    URL: ${sol.url}`
).join('\n')}

Stack Trace:
${error.stackTrace}`;
  }

  private async scoreAndValidateSuggestions(
    suggestions: RawFixSuggestion[],
    error: TestFailure,
    classification: ErrorClassification,
    webSolutions: WebSolutionResults
  ): Promise<FixSuggestion[]> {
    const validatedSuggestions: FixSuggestion[] = [];

    for (const rawSuggestion of suggestions) {
      // 1. Validate suggestion feasibility
      const feasibilityScore = await this.solutionValidator.validateFeasibility(rawSuggestion, error);
      
      // 2. Calculate confidence score
      const confidenceScore = await this.confidenceScorer.calculateConfidence(
        rawSuggestion, classification, webSolutions
      );

      // 3. Assess implementation difficulty
      const difficultyAssessment = await this.assessImplementationDifficulty(rawSuggestion, error);

      // 4. Generate risk assessment
      const riskAssessment = await this.generateRiskAssessment(rawSuggestion, error);

      // 5. Create verification steps
      const verificationSteps = await this.generateVerificationSteps(rawSuggestion, error);

      if (feasibilityScore > 0.6 && confidenceScore > 0.5) {
        validatedSuggestions.push({
          id: rawSuggestion.id,
          title: rawSuggestion.title,
          description: rawSuggestion.description,
          implementation: {
            steps: rawSuggestion.implementation?.steps || [],
            codeDiff: await this.generateCodeDiff(rawSuggestion, error),
            estimatedTime: difficultyAssessment.estimatedTime,
            difficulty: difficultyAssessment.difficulty,
            automatable: difficultyAssessment.automatable,
            requiresManualIntervention: difficultyAssessment.requiresManualIntervention
          },
          confidence: confidenceScore,
          alternatives: rawSuggestion.alternatives || [],
          risks: riskAssessment,
          verification: verificationSteps,
          estimatedImpact: {
            fixProbability: feasibilityScore,
            timeToImplement: difficultyAssessment.estimatedTime,
            riskLevel: this.calculateRiskLevel(riskAssessment),
            knowledgeRequired: difficultyAssessment.difficulty
          },
          prerequisites: rawSuggestion.prerequisites || [],
          relatedSuggestions: [],
          metadata: {
            source: rawSuggestion.source,
            generatedAt: new Date().toISOString(),
            validationScore: feasibilityScore,
            communitySupport: this.calculateCommunitySupport(rawSuggestion, webSolutions)
          }
        });
      }
    }

    return validatedSuggestions;
  }

  private calculateOverallScore(suggestion: FixSuggestion): number {
    const weights = {
      confidence: 0.4,
      feasibility: 0.3,
      difficulty: 0.2,
      communitySupport: 0.1
    };

    const difficultyScore = suggestion.implementation.difficulty === 'easy' ? 1 : 
                           suggestion.implementation.difficulty === 'medium' ? 0.7 : 0.4;

    return (
      suggestion.confidence * weights.confidence +
      suggestion.estimatedImpact.fixProbability * weights.feasibility +
      difficultyScore * weights.difficulty +
      (suggestion.metadata?.communitySupport || 0) * weights.communitySupport
    );
  }
}

interface RawFixSuggestion {
  id: string;
  title: string;
  description: string;
  category?: string;
  type?: string;
  implementation?: any;
  alternatives?: any[];
  prerequisites?: string[];
  source: 'primary' | 'alternative' | 'preventive';
}

interface SuggestionEngineConfig {
  minConfidenceThreshold: number;
  maxSuggestions: number;
  enableRiskAssessment: boolean;
  enableCodeDiffs: boolean;
  enableVerificationSteps: boolean;
}
```

#### 6.2 CLI Interface Implementation

**Comprehensive CLI Interface:**
```typescript
// src/cli/index.ts
import { Command } from 'commander';
import chalk from 'chalk';
import inquirer from 'inquirer';
import ora from 'ora';
import { ErrorIntelligenceEngine } from '../core/ErrorIntelligenceEngine';
import { TestValidator } from '../components/validator/TestValidator';
import { HTMLReporter } from '../components/reporter/HTMLReporter';
import { CLIReporter } from '../components/reporter/CLIReporter';
import { ConfigLoader } from '../utils/config/ConfigLoader';

const program = new Command();

program
  .name('neurolink-ai')
  .description('AI-powered error intelligence and test validation')
  .version('1.0.0');

// Analyze command
program
  .command('analyze')
  .description('Analyze a specific test failure')
  .option('-f, --test-file <file>', 'Test file path')
  .option('-l, --failure-line <line>', 'Line number where failure occurred')
  .option('-m, --error-message <message>', 'Error message to analyze')
  .option('-s, --stack-trace <trace>', 'Stack trace of the error')
  .option('-o, --output <format>', 'Output format (console|html|json)', 'console')
  .option('--no-web-search', 'Disable web research for solutions')
  .option('--no-visual-analysis', 'Disable visual analysis for UI errors')
  .option('--confidence-threshold <threshold>', 'Minimum confidence threshold for suggestions', '0.7')
  .action(async (options) => {
    const spinner = ora('Initializing error analysis...').start();
    
    try {
      // Load configuration
      const config = await ConfigLoader.load();
      const engine = new ErrorIntelligenceEngine(config);
      
      // Build test failure object from options
      const testFailure = await buildTestFailureFromOptions(options);
      
      spinner.text = 'Analyzing error with AI...';
      
      // Perform comprehensive analysis
      const analysisReport = await engine.analyzeError(testFailure);
      
      spinner.succeed('Analysis completed successfully!');
      
      // Output results based on format
      await outputAnalysisResults(analysisReport, options.output);
      
    } catch (error) {
      spinner.fail(`Analysis failed: ${error.message}`);
      console.error(chalk.red(error.stack));
      process.exit(1);
    }
  });

// Validate command
program
  .command('validate')
  .description('Validate test suite quality and effectiveness')
  .option('-d, --test-directory <directory>', 'Test directory to validate', './tests')
  .option('-o, --output <file>', 'Output report file (HTML format)')
  .option('--coverage-threshold <threshold>', 'Coverage threshold for validation', '80')
  .option('--quality-threshold <threshold>', 'Quality score threshold', '75')
  .option('--include-suggestions', 'Include improvement suggestions in report')
  .option('--format <format>', 'Report format (html|json|console)', 'html')
  .action(async (options) => {
    const spinner = ora('Discovering test files...').start();
    
    try {
      const config = await ConfigLoader.load();
      const validator = new TestValidator(config);
      
      spinner.text = 'Analyzing test suite quality...';
      
      const validationReport = await validator.validateTestSuite(options.testDirectory);
      
      spinner.text = 'Generating validation report...';
      
      if (options.format === 'html' && options.output) {
        const htmlReporter = new HTMLReporter();
        await htmlReporter.generateValidationReport(validationReport, options.output);
        spinner.succeed(`Validation report generated: ${options.output}`);
      } else {
        const cliReporter = new CLIReporter();
        await cliReporter.displayValidationReport(validationReport);
        spinner.succeed('Validation completed!');
      }
      
      // Exit with error code if quality thresholds not met
      if (validationReport.summary.qualityScore < parseFloat(options.qualityThreshold)) {
        console.log(chalk.yellow(`\nWarning: Quality score ${validationReport.summary.qualityScore} is below threshold ${options.qualityThreshold}`));
        process.exit(1);
      }
      
    } catch (error) {
      spinner.fail(`Validation failed: ${error.message}`);
      console.error(chalk.red(error.stack));
      process.exit(1);
    }
  });

// Interactive debugging session
program
  .command('debug')
  .description('Start interactive debugging session')
  .option('--mode <mode>', 'Debug mode (guided|expert)', 'guided')
  .action(async (options) => {
    console.log(chalk.blue.bold('ğŸ” Neurolink AI Interactive Debugging Session\n'));
    
    try {
      const config = await ConfigLoader.load();
      const session = new InteractiveDebugSession(config);
      
      if (options.mode === 'guided') {
        await session.startGuidedSession();
      } else {
        await session.startExpertSession();
      }
      
    } catch (error) {
      console.error(chalk.red(`Debug session failed: ${error.message}`));
      process.exit(1);
    }
  });

// Watch mode for continuous analysis
program
  .command('watch')
  .description('Watch test directory for failures and analyze them automatically')
  .option('-d, --test-directory <directory>', 'Test directory to watch', './tests')
  .option('--auto-analyze', 'Automatically analyze failures as they occur')
  .option('--notification', 'Enable desktop notifications')
  .action(async (options) => {
    console.log(chalk.green.bold('ğŸ‘€ Starting watch mode...\n'));
    
    try {
      const config = await ConfigLoader.load();
      const watcher = new TestWatcher(config);
      
      await watcher.startWatching(options.testDirectory, {
        autoAnalyze: options.autoAnalyze,
        notifications: options.notification
      });
      
    } catch (error) {
      console.error(chalk.red(`Watch mode failed: ${error.message}`));
      process.exit(1);
    }
  });

// Report generation command
program
  .command('report')
  .description('Generate comprehensive analysis report')
  .option('-i, --input <file>', 'Input analysis data file (JSON)')
  .option('-o, --output <file>', 'Output report file', 'neurolink-report.html')
  .option('--include-screenshots', 'Include screenshots in report')
  .option('--include-solutions', 'Include community solutions in report')
  .option('--template <template>', 'Report template (default|detailed|executive)', 'default')
  .action(async (options) => {
    const spinner = ora('Generating comprehensive report...').start();
    
    try {
      const htmlReporter = new HTMLReporter();
      const analysisData = options.input ? 
        await loadAnalysisData(options.input) : 
        await gatherCurrentAnalysisData();
      
      spinner.text = 'Rendering report template...';
      
      await htmlReporter.generateComprehensiveReport(analysisData, options.output, {
        includeScreenshots: options.includeScreenshots,
        includeSolutions: options.includeSolutions,
        template: options.template
      });
      
      spinner.succeed(`Report generated successfully: ${options.output}`);
      
      // Optionally open report in browser
      const { openReport } = await inquirer.prompt([{
        type: 'confirm',
        name: 'openReport',
        message: 'Would you like to open the report in your browser?',
        default: true
      }]);
      
      if (openReport) {
        const open = await import('open');
        await open.default(options.output);
      }
      
    } catch (error) {
      spinner.fail(`Report generation failed: ${error.message}`);
      console.error(chalk.red(error.stack));
      process.exit(1);
    }
  });

// Configuration command
program
  .command('configure')
  .description('Configure Neurolink AI settings')
  .option('--neurolink-key <key>', 'Neurolink API key')
  .option('--search-api-key <key>', 'Google Search API key')
  .option('--provider <provider>', 'Default AI provider')
  .option('--interactive', 'Interactive configuration setup')
  .action(async (options) => {
    try {
      if (options.interactive) {
        await runInteractiveConfiguration();
      } else {
        await updateConfiguration(options);
      }
      
      console.log(chalk.green('âœ… Configuration updated successfully!'));
      
    } catch (error) {
      console.error(chalk.red(`Configuration failed: ${error.message}`));
      process.exit(1);
    }
  });

// Helper functions
async function buildTestFailureFromOptions(options: any): Promise<TestFailure> {
  let testFailure: Partial<TestFailure> = {};
  
  if (options.testFile) {
    // Read test file and extract context
    const fileContent = await fs.readFile(options.testFile, 'utf-8');
    const testInfo = await extractTestInfo(fileContent, options.failureLine);
    testFailure = { ...testFailure, ...testInfo };
  }
  
  if (!options.errorMessage && !testFailure.message) {
    // Interactive prompts to gather missing information
    const answers = await inquirer.prompt([
      {
        type: 'input',
        name: 'errorMessage',
        message: 'Enter the error message:',
        validate: (input) => input.length > 0 || 'Error message is required'
      },
      {
        type: 'list',
        name: 'errorType',
        message: 'Select error type:',
        choices: ['runtime', 'syntax', 'assertion', 'timeout', 'network', 'configuration']
      },
      {
        type: 'input',
        name: 'stackTrace',
        message: 'Enter stack trace (optional):',
        default: ''
      },
      {
        type: 'list',
        name: 'framework',
        message: 'Select testing framework:',
        choices: ['jest', 'mocha', 'cypress', 'playwright', 'vitest', 'other']
      }
    ]);
    
    testFailure = {
      ...testFailure,
      message: answers.errorMessage,
      type: answers.errorType,
      stackTrace: answers.stackTrace,
      context: {
        ...testFailure.context,
        framework: answers.framework
      }
    };
  }
  
  // Fill in required fields with defaults
  return {
    id: `cli_${Date.now()}`,
    type: options.errorMessage ? 'runtime' : testFailure.type || 'runtime',
    message: options.errorMessage || testFailure.message || '',
    stackTrace: options.stackTrace || testFailure.stackTrace || '',
    testFile: options.testFile || './unknown.test.js',
    lineNumber: options.failureLine ? parseInt(options.failureLine) : testFailure.lineNumber,
    context: {
      testName: testFailure.context?.testName || 'Unknown Test',
      testSuite: testFailure.context?.testSuite || 'CLI Analysis',
      framework: testFailure.context?.framework || 'jest',
      environment: 'development',
      dependencies: testFailure.context?.dependencies || [],
      configuration: {}
    },
    timestamp: new Date().toISOString(),
    severity: 'medium',
    metadata: {
      testRunner: 'cli',
      testFramework: testFailure.context?.framework || 'jest',
      operatingSystem: process.platform
    }
  } as TestFailure;
}

async function outputAnalysisResults(report: ErrorAnalysisReport, format: string): Promise<void> {
  switch (format) {
    case 'html':
      const htmlReporter = new HTMLReporter();
      const outputFile = `analysis-${report.id}.html`;
      await htmlReporter.generateAnalysisReport(report, outputFile);
      console.log(chalk.green(`\nğŸ“„ HTML report generated: ${outputFile}`));
      break;
      
    case 'json':
      const jsonFile = `analysis-${report.id}.json`;
      await fs.writeFile(jsonFile, JSON.stringify(report, null, 2));
      console.log(chalk.green(`\nğŸ“Š JSON report saved: ${jsonFile}`));
      break;
      
    case 'console':
    default:
      const cliReporter = new CLIReporter();
      await cliReporter.displayAnalysisReport(report);
      break;
  }
}

// Interactive debugging session
class InteractiveDebugSession {
  constructor(private config: any) {}
  
  async startGuidedSession(): Promise<void> {
    console.log(chalk.cyan('ğŸ¯ Guided Debugging Session'));
    console.log(chalk.gray('I\'ll help you step through the debugging process.\n'));
    
    const { sessionType } = await inquirer.prompt([{
      type: 'list',
      name: 'sessionType',
      message: 'What would you like to debug?',
      choices: [
        { name: 'ğŸ› Analyze a specific test failure', value: 'failure' },
        { name: 'ğŸ“Š Validate test suite quality', value: 'validation' },
        { name: 'ğŸ” Investigate flaky tests', value: 'flakiness' },
        { name: 'ğŸ“ˆ Review test coverage gaps', value: 'coverage' }
      ]
    }]);
    
    switch (sessionType) {
      case 'failure':
        await this.debugTestFailure();
        break;
      case 'validation':
        await this.debugTestValidation();
        break;
      case 'flakiness':
        await this.debugFlakyTests();
        break;
      case 'coverage':
        await this.debugCoverageGaps();
        break;
    }
  }
  
  private async debugTestFailure(): Promise<void> {
    const answers = await inquirer.prompt([
      {
        type: 'input',
        name: 'testFile',
        message: 'Enter the path to your failing test file:',
        validate: (input) => input.length > 0 || 'Test file path is required'
      },
      {
        type: 'confirm',
        name: 'hasErrorMessage',
        message: 'Do you have the error message ready?',
        default: true
      }
    ]);
    
    if (answers.hasErrorMessage) {
      const { errorMessage } = await inquirer.prompt([{
        type: 'editor',
        name: 'errorMessage',
        message: 'Paste your error message and stack trace:'
      }]);
      
      console.log(chalk.yellow('\nğŸ”„ Analyzing your test failure...\n'));
      
      // Perform analysis with gathered information
      const engine = new ErrorIntelligenceEngine(this.config);
      const testFailure = await this.buildTestFailureFromSession({
        testFile: answers.testFile,
        errorMessage
      });
      
      const report = await engine.analyzeError(testFailure);
      
      const cliReporter = new CLIReporter();
      await cliReporter.displayAnalysisReport(report);
      
      // Offer to apply suggestions
      if (report.suggestions.length > 0) {
        const { applySuggestion } = await inquirer.prompt([{
          type: 'confirm',
          name: 'applySuggestion',
          message: 'Would you like to apply one of the suggested fixes?',
          default: false
        }]);
        
        if (applySuggestion) {
          await this.applySuggestionInteractively(report.suggestions);
        }
      }
    }
  }
  
  private async applySuggestionInteractively(suggestions: FixSuggestion[]): Promise<void> {
    const { selectedSuggestion } = await inquirer.prompt([{
      type: 'list',
      name: 'selectedSuggestion',
      message: 'Select a suggestion to apply:',
      choices: suggestions.map((suggestion, index) => ({
        name: `${suggestion.title} (${Math.round(suggestion.confidence * 100)}% confidence)`,
        value: index
      }))
    }]);
    
    const suggestion = suggestions[selectedSuggestion];
    
    console.log(chalk.blue('\nğŸ“‹ Implementation Steps:'));
    suggestion.implementation.steps.forEach((step, index) => {
      console.log(`${index + 1}. ${step.action}`);
      if (step.code) {
        console.log(chalk.gray(`   Code: ${step.code}`));
      }
    });
    
    const { proceed } = await inquirer.prompt([{
      type: 'confirm',
      name: 'proceed',
      message: 'Proceed with applying this fix?',
      default: false
    }]);
    
    if (proceed) {
      console.log(chalk.green('âœ… Fix applied! Please test your changes.'));
    }
  }
}

// Test watcher for continuous monitoring
class TestWatcher {
  constructor(private config: any) {}
  
  async startWatching(directory: string, options: any): Promise<void> {
    const chokidar = await import('chokidar');
    
    console.log(chalk.blue(`Watching: ${directory}`));
    console.log(chalk.gray('Press Ctrl+C to stop watching\n'));
    
    const watcher = chokidar.watch(directory, {
      ignored: /node_modules/,
      persistent: true
    });
    
    watcher.on('change', async (filePath) => {
      if (filePath.includes('.test.') || filePath.includes('.spec.')) {
        console.log(chalk.yellow(`\nğŸ“ Test file changed: ${filePath}`));
        
        if (options.autoAnalyze) {
          console.log(chalk.blue('ğŸ” Running automatic analysis...'));
          // Trigger analysis for the changed file
          await this.analyzeChangedFile(filePath);
        }
      }
    });
    
    // Keep the process running
    process.on('SIGINT', () => {
      console.log(chalk.blue('\nğŸ‘‹ Stopping watch mode...'));
      watcher.close();
      process.exit(0);
    });
  }
}

async function runInteractiveConfiguration(): Promise<void> {
  console.log(chalk.blue.bold('ğŸ”§ Neurolink AI Configuration Setup\n'));
  
  const answers = await inquirer.prompt([
    {
      type: 'password',
      name: 'neurolinkKey',
      message: 'Enter your Neurolink API key:',
      mask: '*',
      validate: (input) => input.length > 0 || 'API key is required'
    },
    {
      type: 'password',
      name: 'searchApiKey',
      message: 'Enter your Google Search API key (optional):',
      mask: '*'
    },
    {
      type: 'list',
      name: 'defaultProvider',
      message: 'Select default AI provider:',
      choices: ['openai', 'anthropic', 'google', 'azure'],
      default: 'openai'
    },
    {
      type: 'confirm',
      name: 'enableAnalytics',
      message: 'Enable usage analytics?',
      default: true
    },
    {
      type: 'number',
      name: 'confidenceThreshold',
      message: 'Set minimum confidence threshold for suggestions (0.1-1.0):',
      default: 0.7,
      validate: (input) => (input >= 0.1 && input <= 1.0) || 'Must be between 0.1 and 1.0'
    }
  ]);
  
  await ConfigLoader.save({
    neurolink: {
      apiKey: answers.neurolinkKey,
      defaultProvider: answers.defaultProvider,
      enableAnalytics: answers.enableAnalytics
    },
    search: {
      googleApiKey: answers.searchApiKey
    },
    analysis: {
      confidenceThreshold: answers.confidenceThreshold
    }
  });
}

// Parse command line arguments
program.parse();

export { program };

---

## ğŸ“ Production Project Structure & Dependencies

### ğŸ¯ Directory Goals & Purposes

#### `/src/core/` - Central Orchestration Hub
**Goal**: Provide main coordination and shared interfaces  
**Purpose**: House the primary ErrorIntelligenceEngine and core coordination logic
```
â”œâ”€â”€ ErrorIntelligenceEngine.ts      // ğŸ¯ Main orchestrator - coordinates all analysis components
â”œâ”€â”€ TestValidator.ts                // ğŸ¯ Test suite validation - assesses test quality and effectiveness  
â””â”€â”€ FailureAnalyzer.ts             // ğŸ¯ Failure pattern analysis - identifies recurring patterns
```

#### `/src/analyzers/` - Specialized Analysis Components
**Goal**: Perform deep analysis of different error types and contexts  
**Purpose**: Extract meaningful insights from failures using specialized analysis techniques
```
â”œâ”€â”€ PuppeteerAnalyzer.ts           // ğŸ¯ Visual failure analysis - DOM, screenshots, performance
â”œâ”€â”€ CodeContextAnalyzer.ts         // ğŸ¯ Code context extraction - AST parsing, imports, scope
â””â”€â”€ LogAnalyzer.ts                 // ğŸ¯ Log pattern analysis - console errors, stack traces
```

#### `/src/research/` - Knowledge Mining & Solution Discovery
**Goal**: Mine community knowledge and find relevant solutions  
**Purpose**: Leverage external sources to provide comprehensive solution recommendations
```
â”œâ”€â”€ WebResearchService.ts          // ğŸ¯ Solution research coordinator - orchestrates multi-source search
â”œâ”€â”€ StackOverflowSearcher.ts       // ğŸ¯ Stack Overflow integration - question/answer mining
â”œâ”€â”€ GitHubSearcher.ts              // ğŸ¯ GitHub Issues integration - issue/solution tracking
â””â”€â”€ SolutionAggregator.ts          // ğŸ¯ Solution consolidation - ranking and relevance analysis
```

#### `/src/suggestions/` - Intelligent Fix Generation
**Goal**: Generate actionable, context-aware fix suggestions  
**Purpose**: Transform analysis into concrete, implementable solutions
```
â”œâ”€â”€ FixSuggestionEngine.ts         // ğŸ¯ AI-powered fix generation - multi-approach solution creation
â”œâ”€â”€ ConfidenceScoring.ts           // ğŸ¯ Solution confidence analysis - reliability assessment
â””â”€â”€ SuggestionValidator.ts         // ğŸ¯ Cross-validation of suggestions - feasibility checking
```

#### `/src/validation/` - Test Quality Assessment
**Goal**: Assess and improve test suite quality  
**Purpose**: Identify weaknesses in existing tests and suggest improvements
```
â”œâ”€â”€ TestQualityValidator.ts        // ğŸ¯ Test suite quality analysis - effectiveness scoring
â”œâ”€â”€ CoverageAnalyzer.ts            // ğŸ¯ Coverage gap identification - missing test scenarios
â””â”€â”€ FlakinessDetector.ts           // ğŸ¯ Flaky test detection - reliability assessment
```

#### `/src/storage/` - Data Persistence & Knowledge Management
**Goal**: Manage persistent data and accumulated knowledge  
**Purpose**: Store patterns, cache results, and build organizational knowledge base
```
â”œâ”€â”€ ErrorDatabase.ts               // ğŸ¯ Error pattern storage - pattern learning and recognition
â”œâ”€â”€ KnowledgeBase.ts               // ğŸ¯ Solution knowledge base - accumulated solution wisdom
â””â”€â”€ CacheManager.ts                // ğŸ¯ Search result caching - performance optimization
```

#### `/src/interfaces/` - User Interaction & Reporting
**Goal**: Provide intuitive interfaces for developers  
**Purpose**: Present analysis results in actionable, accessible formats
```
â”œâ”€â”€ CLI.ts                         // ğŸ¯ Command-line interface - developer workflow integration
â”œâ”€â”€ Dashboard.ts                   // ğŸ¯ Web dashboard - visual analysis presentation
â””â”€â”€ ReportGenerator.ts             // ğŸ¯ HTML report generation - comprehensive result documentation
```

#### `/src/types/` - Type Safety & Contracts
**Goal**: Ensure type safety and clear contracts between components  
**Purpose**: Define comprehensive TypeScript types for all data structures
```
â”œâ”€â”€ ErrorTypes.ts                  // ğŸ¯ Error-related type definitions - failure classification types
â”œâ”€â”€ TestTypes.ts                   // ğŸ¯ Test validation types - quality assessment structures
â”œâ”€â”€ AnalysisTypes.ts               // ğŸ¯ Analysis result types - comprehensive analysis data
â””â”€â”€ SuggestionTypes.ts             // ğŸ¯ Fix suggestion types - solution recommendation structures
```

### ğŸ“‹ Supporting Infrastructure

#### `/templates/` - Presentation Templates
**Goal**: Provide consistent, professional output formatting
```
â”œâ”€â”€ report.html                    // ğŸ¯ HTML report template - comprehensive analysis presentation
â””â”€â”€ email-notification.html        // ğŸ¯ Email notification template - alert formatting
```

#### `/config/` - Configuration Management
**Goal**: Centralized configuration for all services and integrations
```
â”œâ”€â”€ neurolink.config.js           // ğŸ¯ Neurolink configuration - AI provider settings
â””â”€â”€ search-apis.config.js         // ğŸ¯ Search API configurations - external service settings
```

#### `/tests/` - Quality Assurance
**Goal**: Ensure reliability and correctness of all components
```
â”œâ”€â”€ unit/                         // ğŸ¯ Unit tests - individual component validation
â”œâ”€â”€ integration/                  // ğŸ¯ Integration tests - component interaction validation
â””â”€â”€ fixtures/                     // ğŸ¯ Test fixtures and sample data - realistic test scenarios
```

#### `/docs/` - Documentation & Guidance
**Goal**: Provide comprehensive documentation for users and maintainers
```
â”œâ”€â”€ api.md                       // ğŸ¯ API documentation - interface specifications
â”œâ”€â”€ setup.md                     // ğŸ¯ Setup instructions - installation and configuration
â””â”€â”€ examples.md                  // ğŸ¯ Usage examples - practical implementation guidance
```

#### `/examples/` - Practical Implementation Examples
**Goal**: Demonstrate practical usage patterns and advanced configurations
```
â”œâ”€â”€ basic-usage.js               // ğŸ¯ Basic usage examples - getting started scenarios
â””â”€â”€ advanced-configuration.js   // ğŸ¯ Advanced configuration examples - power user setups
```

### Dependencies
```json
{
  "dependencies": {
    "@juspay/neurolink": "^1.0.0",
    "puppeteer": "^21.0.0",
    "cheerio": "^1.0.0-rc.12",
    "googleapis": "^126.0.0",
    "sqlite3": "^5.1.6",
    "typescript": "^5.0.0",
    "express": "^4.18.2",
    "ws": "^8.14.0",
    "chalk": "^5.0.0",
    "inquirer": "^9.0.0",
    "commander": "^11.0.0",
    "mustache": "^4.2.0",
    "node-html-parser": "^6.1.0",
    "diff": "^5.1.0"
  },
  "devDependencies": {
    "@types/node": "^20.0.0",
    "@types/express": "^4.17.17",
    "@types/ws": "^8.5.5",
    "@types/inquirer": "^9.0.0",
    "jest": "^29.0.0",
    "@typescript-eslint/eslint-plugin": "^6.0.0",
    "prettier": "^3.0.0",
    "nodemon": "^3.0.0"
  }
}
```

---

## Implementation Workflows

### Workflow 1: Error Intelligence Pipeline
```
Test Failure Detected â†’ Error Classification â†’ Context Analysis â†’ 
Visual Analysis (if UI) â†’ Pattern Recognition â†’ Web Research â†’ 
Fix Suggestion Generation â†’ Confidence Scoring â†’ Report Generation
```

### Workflow 2: Test Validation Pipeline
```
Test Discovery â†’ Quality Analysis â†’ Coverage Gap Detection â†’ 
Flakiness Assessment â†’ Effectiveness Scoring â†’ Improvement Suggestions â†’ 
Validation Report Generation
```

### Workflow 3: Continuous Learning Pipeline
```
Solution Application â†’ Outcome Tracking â†’ Pattern Learning â†’ 
Knowledge Base Update â†’ Improved Future Suggestions
```

---

## Success Metrics & Quality Targets

### Phase 1.5 Success Metrics
1. **Error Analysis Accuracy**: >85% of suggestions lead to successful fixes
2. **Time to Resolution**: 60% reduction in debugging time for developers
3. **Solution Relevance**: >90% of web research results are relevant to the specific error
4. **Test Validation Coverage**: Identify 95% of obvious test quality issues
5. **Developer Satisfaction**: Developers find suggestions actionable and helpful
6. **False Positive Rate**: <15% of suggestions are irrelevant or incorrect

### Quality Targets
- **Analysis Speed**: <30 seconds for error analysis including web research
- **Report Generation**: <5 seconds for comprehensive HTML reports
- **Memory Usage**: <500MB during peak analysis operations
- **Accuracy Confidence**: >80% confidence score for primary suggestions
- **Knowledge Base Growth**: Learn from 100% of applied solutions

---

## Phase 2: Automated Fix Application & Integration (Future Goals)
**Duration**: 1-3 days
**Priority**: Medium - Automation layer building on error intelligence

### Automated Fix Application Features
- **Automated Fix Application**: Automatically applies fixes with confidence scoring
- **Git Integration**: Creates branches, commits, automated PRs with detailed descriptions
- **CLI Tools**: Interactive fix application, batch processing
- **CI/CD Integration**: GitHub Actions workflows, automated fix PRs in pipelines
- **IDE Extensions**: VS Code/IntelliJ plugins with real-time error fixing

### Advanced Testing Capabilities
- **API Testing**: REST endpoint testing, GraphQL testing
- **Security Testing**: XSS, CSRF, authentication testing
- **Performance Testing**: Load testing, memory profiling

---

## Phase 3: AI-Powered Intelligent Test Generation
**Duration**: 7-10 days
**Priority**: Medium - Advanced capability building on error intelligence foundation

### Strategic Approach: Knowledge-Driven Test Generation

Unlike traditional test generators that create tests blindly, Phase 3 leverages intelligence from previous phases:
- **Error patterns** learned from Phase 1.5 analysis
- **Coverage gaps** identified during test validation
- **Code context understanding** from failure analysis
- **Community solutions** patterns from web research
- **Quality metrics** from existing test analysis

#### 3.1 Intelligent Test Strategy Engine
**Duration**: Days 1-2
**Objective**: Analyze codebase and determine what tests are actually needed

```typescript
class TestStrategyEngine {
  async analyzeCodebaseForTestNeeds(
    codebaseDirectory: string,
    existingTestAnalysis: TestValidationReport,
    errorPatterns: ErrorPattern[]
  ): Promise<TestGenerationStrategy> {
    
    // 1. Code analysis and understanding
    const codeAnalysis = await this.analyzeCodeStructure(codebaseDirectory);
    
    // 2. Identify critical paths and edge cases
    const criticalPaths = await this.identifyCriticalPaths(codeAnalysis);
    
    // 3. Map coverage gaps to actual business logic
    const prioritizedGaps = await this.prioritizeCoverageGaps(
      existingTestAnalysis.coverageGaps, 
      criticalPaths,
      errorPatterns
    );
    
    // 4. Generate test generation strategy
    return this.createTestStrategy(prioritizedGaps, codeAnalysis);
  }
}
```

**Test Strategy Categories:**
1. **Critical Path Tests**: Core business logic and user workflows
2. **Error-Prone Pattern Tests**: Based on historical failure analysis
3. **Edge Case Tests**: Boundary conditions and unusual scenarios
4. **Integration Point Tests**: Component interactions and data flow
5. **Regression Prevention Tests**: Tests that prevent recurring errors

#### 3.2 Smart Test Generation Engine
**Duration**: Days 2-4
**Objective**: Generate contextually relevant tests using AI understanding

```typescript
class SmartTestGenerator {
  async generateTests(
    strategy: TestGenerationStrategy,
    codeContext: CodeContext
  ): Promise<GeneratedTestSuite> {
    
    const generatedTests = [];
    
    for (const testTarget of strategy.targets) {
      // Generate tests using multiple AI approaches
      const testApproaches = await Promise.all([
        this.generateFunctionalTests(testTarget, codeContext),
        this.generateEdgeCaseTests(testTarget, codeContext),
        this.generateErrorHandlingTests(testTarget, codeContext),
        this.generateIntegrationTests(testTarget, codeContext)
      ]);
      
      // Consolidate and optimize generated tests
      const optimizedTests = await this.optimizeTestSuite(testApproaches);
      generatedTests.push(...optimizedTests);
    }
    
    return {
      tests: generatedTests,
      coverage: this.calculateProjectedCoverage(generatedTests),
      quality: this.assessGeneratedTestQuality(generatedTests),
      recommendations: this.generateTestingRecommendations(generatedTests)
    };
  }
}
```

#### 3.3 Multi-Framework Test Code Generation
**Duration**: Days 4-6
**Objective**: Generate actual test code for different testing frameworks

**Supported Frameworks:**
- **Jest/Vitest**: Unit and integration tests
- **React Testing Library**: Component tests
- **Cypress/Playwright**: E2E tests
- **Supertest**: API tests

```typescript
class TestCodeGenerator {
  async generateTestCode(
    testSpecs: TestSpecification[],
    framework: TestFramework,
    codeStyle: CodeStyle
  ): Promise<GeneratedTestFiles> {
    
    const testFiles = [];
    
    for (const spec of testSpecs) {
      const testCode = await this.neurolink.generate({
        provider: 'openai/gpt-4o',
        input: { 
          text: this.buildTestGenerationPrompt(spec, framework, codeStyle) 
        },
        context: {
          testType: spec.type,
          framework: framework.name,
          complexity: spec.complexity
        }
      });
      
      // Validate and optimize generated code
      const validatedCode = await this.validateGeneratedTest(testCode, spec);
      const optimizedCode = await this.optimizeTestCode(validatedCode);
      
      testFiles.push({
        filePath: this.generateTestFilePath(spec),
        content: optimizedCode,
        spec: spec,
        metadata: {
          framework: framework.name,
          estimatedCoverage: spec.projectedCoverage,
          complexity: spec.complexity,
          generatedAt: new Date().toISOString()
        }
      });
    }
    
    return testFiles;
  }
}
```

#### 3.4 Test Quality Validation & Optimization
**Duration**: Days 6-7
**Objective**: Ensure generated tests meet quality standards

```typescript
class GeneratedTestValidator {
  async validateGeneratedTests(
    generatedTests: GeneratedTestFiles[]
  ): Promise<TestValidationResults> {
    
    const validationResults = [];
    
    for (const testFile of generatedTests) {
      // 1. Syntax and compilation validation
      const syntaxCheck = await this.validateSyntax(testFile);
      
      // 2. Best practices compliance
      const bestPracticesCheck = await this.validateBestPractices(testFile);
      
      // 3. Effectiveness assessment
      const effectivenessCheck = await this.assessTestEffectiveness(testFile);
      
      // 4. Performance impact assessment
      const performanceCheck = await this.assessPerformanceImpact(testFile);
      
      // 5. AI-powered quality review
      const aiQualityReview = await this.performAIQualityReview(testFile);
      
      validationResults.push({
        testFile,
        syntaxCheck,
        bestPracticesCheck,
        effectivenessCheck,
        performanceCheck,
        aiQualityReview,
        overallScore: this.calculateOverallQuality([
          syntaxCheck, bestPracticesCheck, effectivenessCheck, 
          performanceCheck, aiQualityReview
        ])
      });
    }
    
    return {
      results: validationResults,
      summary: this.generateValidationSummary(validationResults),
      recommendations: this.generateImprovementRecommendations(validationResults)
    };
  }
}
```

#### 3.5 Contextual Test Generation Based on Codebase Analysis
**Duration**: Days 7-8
**Objective**: Generate tests that understand the actual codebase context

**Smart Features:**
- **Import Analysis**: Automatically determines correct imports and dependencies
- **Type Inference**: Understands TypeScript types and generates appropriate test data
- **Mock Generation**: Creates intelligent mocks for dependencies
- **Data Factory Creation**: Generates test data factories and fixtures

```typescript
class ContextualTestGenerator {
  async generateContextualTests(
    targetFile: string,
    testType: TestType
  ): Promise<ContextualTestSuite> {
    
    // 1. Analyze target file structure
    const fileAnalysis = await this.analyzeTargetFile(targetFile);
    
    // 2. Extract functions, classes, and dependencies
    const codeStructure = await this.extractCodeStructure(fileAnalysis);
    
    // 3. Generate appropriate test scenarios
    const testScenarios = await this.generateTestScenarios(codeStructure, testType);
    
    // 4. Create test data and mocks
    const testData = await this.generateTestData(codeStructure);
    const mocks = await this.generateMocks(codeStructure.dependencies);
    
    // 5. Generate comprehensive test code
    const testCode = await this.generateComprehensiveTestCode({
      scenarios: testScenarios,
      testData,
      mocks,
      codeStructure,
      targetFile
    });
    
    return {
      testCode,
      testData,
      mocks,
      coverage: this.estimateCoverage(testScenarios, codeStructure),
      complexity: this.assessTestComplexity(testCode)
    };
  }
}
```

#### 3.6 CLI Integration & Developer Experience
**Duration**: Days 8-10
**Objective**: Seamless integration with developer workflow

**CLI Commands:**
```bash
# Generate tests for specific file
neurolink-ai generate --file="src/components/UserProfile.tsx" --type="component"

# Generate tests based on coverage gaps
neurolink-ai generate --fill-gaps --test-directory="./tests" --coverage-threshold=80

# Generate tests for error-prone patterns
neurolink-ai generate --error-patterns --based-on-analysis="./error-analysis-report.json"

# Interactive test generation
neurolink-ai generate --interactive --framework="jest" --style="typescript"

# Batch generation for entire directory
neurolink-ai generate --directory="src/utils" --batch --review-before-create
```

**Developer Experience Features:**
- **Preview Mode**: Show generated tests before creating files
- **Interactive Approval**: Approve/reject individual tests
- **Incremental Generation**: Generate tests progressively
- **Framework Detection**: Auto-detect existing testing framework
- **Code Style Matching**: Match existing code style and patterns

### Integration with Previous Phases

#### Phase 1.5 â†’ Phase 3 Data Flow:
- **Error Patterns** â†’ Generate tests that prevent recurring errors
- **Coverage Gaps** â†’ Generate tests to fill identified gaps
- **Quality Issues** â†’ Generate tests following best practices
- **Code Context** â†’ Generate contextually appropriate tests

#### Phase 2 â†’ Phase 3 Integration:
- **Automated Fix Application** â†’ Generate tests for fixed code
- **Git Integration** â†’ Create test generation commits/PRs
- **CI/CD Integration** â†’ Generate tests in pipeline

### Phase 3 Success Metrics

1. **Test Generation Accuracy**: >90% of generated tests compile and run successfully
2. **Coverage Improvement**: Generated tests increase coverage by target amount
3. **Quality Score**: Generated tests score >85% on quality metrics
4. **Developer Adoption**: >80% of generated tests are accepted by developers
5. **Error Prevention**: Generated tests catch 75% of error patterns from Phase 1.5 analysis
6. **Time Savings**: 70% reduction in manual test writing time

---

## Complete Phase Progression

### **Phase 1.5: Error Intelligence & Test Validation** (5-7 days)
- Analyze failures, validate existing tests, build knowledge base

### **Phase 2: Automation & Fix Application** (5-7 days)  
- Automated fix application, Git integration, CI/CD automation

### **Phase 3: Intelligent Test Generation** (7-10 days)
- Smart test generation based on analysis insights and coverage gaps

### **Phase 4: Analytics & Optimization** (3-5 days)
- Advanced analytics, trend analysis, continuous improvement

This progression creates a **complete AI testing ecosystem** where:
1. **Phase 1.5** teaches the system about your codebase and failure patterns
2. **Phase 2** automates the fix application process
3. **Phase 3** generates intelligent tests based on learned insights
4. **Phase 4** provides ongoing optimization and analytics

---

## Long-Term Vision: Advanced Testing Capabilities (Future)

### Visual Testing & Advanced Capabilities
- **Component Testing**: Automated UI component test generation
- **Visual Testing**: Screenshot comparison, layout validation

---

## Risk Assessment & Mitigation

### Technical Risks
1. **AI Provider Reliability**: Mitigated by multi-provider architecture with Neurolink
2. **Solution Quality Variability**: Addressed through confidence scoring and cross-validation
3. **Web Research Rate Limits**: Managed through intelligent caching and query optimization
4. **False Positive Suggestions**: Reduced through community validation and learning feedback

### Operational Risks
1. **Developer Adoption**: Mitigated through clear CLI interface and immediate value demonstration
2. **Integration Complexity**: Addressed through simple setup process and comprehensive documentation
3. **Maintenance Overhead**: Managed through automated learning and knowledge base updates

---

## Getting Started

### Prerequisites
- Node.js 18+ 
- Neurolink SDK access
- Google Search API key (for web research)
- TypeScript development environment

### Quick Setup
```bash
# Install the CLI globally
npm install -g @your-org/neurolink-error-intelligence

# Configure API keys
neurolink-ai configure --neurolink-key=your_key --search-api-key=your_search_key

# Analyze your first test failure
neurolink-ai analyze --test-file="./tests/failing-test.js"

# Validate your test suite
neurolink-ai validate --test-directory="./tests" --output="analysis-report.html"
```

---

This focused Phase 1.5 implementation creates a powerful error intelligence system that provides immediate value through sophisticated analysis and actionable suggestions, establishing the foundation for future automation capabilities while respecting the current constraints and requirements.
